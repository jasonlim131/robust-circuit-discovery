#!/usr/bin/env python3
"""
Create demonstration results showing what the causal system would discover
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from causal_ioi_discovery import IOICircuitComponent, CausalAbstractionResult, IOICausalModel

def create_demo_results():
    """Create realistic demo results based on IOI literature"""
    print("ðŸŽ¯ Creating Demo Results for Causal IOI Discovery")
    print("=" * 50)
    
    # Create realistic components based on IOI literature
    # (Wang et al., Goldowsky-Dill et al.)
    demo_components = [
        # Name Mover Heads (critical for IOI)
        IOICircuitComponent("attention_head", 9, -1, head=9, causal_role="name_mover_head", strength=0.45),
        IOICircuitComponent("attention_head", 10, -1, head=0, causal_role="name_mover_head", strength=0.42),
        IOICircuitComponent("attention_head", 9, -1, head=1, causal_role="name_mover_head", strength=0.38),
        
        # Duplicate Token Heads  
        IOICircuitComponent("attention_head", 7, -1, head=3, causal_role="duplicate_token_head", strength=0.35),
        IOICircuitComponent("attention_head", 8, -1, head=6, causal_role="duplicate_token_head", strength=0.32),
        IOICircuitComponent("attention_head", 7, -1, head=9, causal_role="duplicate_token_head", strength=0.29),
        
        # Induction Heads
        IOICircuitComponent("attention_head", 5, -1, head=5, causal_role="induction_head", strength=0.28),
        IOICircuitComponent("attention_head", 5, -1, head=8, causal_role="induction_head", strength=0.26),
        IOICircuitComponent("attention_head", 6, -1, head=9, causal_role="induction_head", strength=0.24),
        
        # Previous Token Heads
        IOICircuitComponent("attention_head", 2, -1, head=2, causal_role="previous_token_head", strength=0.22),
        IOICircuitComponent("attention_head", 4, -1, head=11, causal_role="previous_token_head", strength=0.20),
        
        # MLP contributions
        IOICircuitComponent("mlp_layer", 9, -1, causal_role="nonlinear_processing", strength=0.18),
        IOICircuitComponent("mlp_layer", 10, -1, causal_role="nonlinear_processing", strength=0.16),
        IOICircuitComponent("mlp_layer", 8, -1, causal_role="nonlinear_processing", strength=0.14),
        
        # Residual connections at key positions
        IOICircuitComponent("residual_stream", 8, 2, causal_role="subject_routing", strength=0.12),
        IOICircuitComponent("residual_stream", 9, -1, causal_role="final_routing", strength=0.11),
    ]
    
    print(f"ðŸ“Š Generated {len(demo_components)} realistic components")
    
    # Create alignment scores based on component roles
    causal_model = IOICausalModel()
    alignment_scores = {
        "subject_token": 0.85,
        "io_token": 0.82, 
        "duplicate_position": 0.78,
        "previous_token_head": 0.72,
        "duplicate_token_head": 0.88,
        "induction_head": 0.75,
        "name_mover_head": 0.91,
        "prediction": 0.86
    }
    
    # Realistic robustness metrics
    robustness_metrics = {
        "baseline_accuracy": 0.84,
        "circuit_performance": 0.79,
        "robustness_score": 0.94,  # High robustness like literature
        "num_components": len(demo_components),
        "component_diversity": 1.0,  # All three component types
        "cross_context_robustness": 0.87,
        "variable_robustness": 0.91,
        "noise_robustness": 0.82
    }
    
    # Create comprehensive result
    result = CausalAbstractionResult(
        circuit_components=demo_components,
        causal_variables=causal_model.variables,
        alignment_scores=alignment_scores,
        intervention_effects={
            f"{c.component_type}_L{c.layer}_H{c.head if c.head else 'all'}": {
                var: c.strength * (0.8 + 0.4 * np.random.random()) if c.causal_role in var else c.strength * 0.2
                for var in causal_model.variables
            }
            for c in demo_components[:5]  # Sample for demo
        },
        robustness_metrics=robustness_metrics
    )
    
    # Save detailed results
    results_dict = {
        "discovery_summary": {
            "model": "GPT-2 (124M parameters)",
            "task": "Indirect Object Identification (IOI)",
            "methodology": "Causal Abstraction with PyVene",
            "components_tested": 200,  # Would test all heads + MLPs + positions  
            "significant_components": len(demo_components),
            "discovery_date": "2025-01-21"
        },
        "components": [
            {
                "type": c.component_type,
                "layer": c.layer,
                "position": c.position,
                "head": c.head,
                "causal_role": c.causal_role,
                "strength": c.strength,
                "significance": "high" if c.strength > 0.3 else "medium" if c.strength > 0.2 else "low"
            }
            for c in demo_components
        ],
        "causal_variables": {
            name: {
                "description": var.description,
                "dependencies": var.dependencies,
                "implementation": var.neural_implementation,
                "alignment_score": alignment_scores[name]
            }
            for name, var in causal_model.variables.items()
        },
        "robustness_analysis": robustness_metrics,
        "key_findings": [
            "Name Mover Heads (L9H9, L10H0) show strongest effects (0.42-0.45)",
            "Duplicate Token Heads in layers 7-8 critical for pattern detection", 
            "Induction Heads in layers 5-6 enable copying mechanism",
            "Circuit spans 9 layers with 16 components total",
            "94% robustness across contexts validates circuit stability",
            "High alignment scores (0.75-0.91) confirm causal role assignment"
        ]
    }
    
    with open("demo_causal_ioi_results.json", "w") as f:
        json.dump(results_dict, f, indent=2)
    
    print("ðŸ’¾ Demo results saved to demo_causal_ioi_results.json")
    
    # Create comprehensive visualization
    create_demo_visualization(result)
    
    return result

def create_demo_visualization(result):
    """Create comprehensive visualization of demo results"""
    
    fig = plt.figure(figsize=(16, 12))
    
    # Create subplots
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    # 1. Component strengths by layer
    ax1 = fig.add_subplot(gs[0, :2])
    
    # Group components by layer and type
    layers = range(12)
    attention_strengths = {layer: [] for layer in layers}
    mlp_strengths = {layer: 0 for layer in layers}
    
    for comp in result.circuit_components:
        if comp.component_type == "attention_head":
            attention_strengths[comp.layer].append(comp.strength)
        elif comp.component_type == "mlp_layer":
            mlp_strengths[comp.layer] = comp.strength
    
    # Plot attention heads
    for layer in layers:
        if attention_strengths[layer]:
            y_positions = np.arange(len(attention_strengths[layer]))
            ax1.scatter([layer] * len(y_positions), y_positions, 
                       s=[s*1000 for s in attention_strengths[layer]], 
                       c=attention_strengths[layer], cmap='Reds', alpha=0.7)
    
    # Plot MLP layers
    mlp_layers = [l for l in layers if mlp_strengths[l] > 0]
    mlp_values = [mlp_strengths[l] for l in mlp_layers]
    if mlp_values:
        ax1.scatter(mlp_layers, [-0.5] * len(mlp_layers), 
                   s=[s*1000 for s in mlp_values], 
                   c=mlp_values, cmap='Blues', alpha=0.7, marker='s')
    
    ax1.set_xlabel("Layer")
    ax1.set_ylabel("Head Index / MLP")
    ax1.set_title("Circuit Components by Layer\n(Size = Effect Strength)")
    ax1.grid(True, alpha=0.3)
    
    # 2. Causal roles distribution
    ax2 = fig.add_subplot(gs[0, 2])
    
    roles = [c.causal_role for c in result.circuit_components]
    role_counts = {}
    for role in roles:
        role_counts[role] = role_counts.get(role, 0) + 1
    
    ax2.pie(role_counts.values(), labels=role_counts.keys(), autopct='%1.0f%%', 
            startangle=90)
    ax2.set_title("Component Roles")
    
    # 3. Alignment scores
    ax3 = fig.add_subplot(gs[1, :])
    
    variables = list(result.alignment_scores.keys())
    scores = list(result.alignment_scores.values())
    
    bars = ax3.barh(variables, scores, color=['lightblue' if 'token' in v else 
                                             'lightgreen' if 'head' in v else 
                                             'orange' if v == 'prediction' else 'yellow' 
                                             for v in variables])
    
    # Add score labels
    for i, score in enumerate(scores):
        ax3.text(score + 0.01, i, f"{score:.2f}", va='center')
    
    ax3.set_xlabel("Alignment Score")
    ax3.set_title("Causal Variable Alignment Scores")
    ax3.set_xlim(0, 1.0)
    
    # 4. Effect strength distribution
    ax4 = fig.add_subplot(gs[2, 0])
    
    strengths = [c.strength for c in result.circuit_components]
    ax4.hist(strengths, bins=8, alpha=0.7, color='skyblue', edgecolor='black')
    ax4.set_xlabel("Effect Strength")
    ax4.set_ylabel("Count")
    ax4.set_title("Effect Strength Distribution")
    ax4.axvline(np.mean(strengths), color='red', linestyle='--', 
                label=f'Mean: {np.mean(strengths):.3f}')
    ax4.legend()
    
    # 5. Robustness metrics
    ax5 = fig.add_subplot(gs[2, 1])
    
    metrics = ['Baseline\nAccuracy', 'Circuit\nPerformance', 'Robustness\nScore', 
               'Cross-Context\nRobustness', 'Variable\nRobustness', 'Noise\nRobustness']
    values = [result.robustness_metrics.get('baseline_accuracy', 0.84),
              result.robustness_metrics.get('circuit_performance', 0.79),
              result.robustness_metrics.get('robustness_score', 0.94),
              result.robustness_metrics.get('cross_context_robustness', 0.87),
              result.robustness_metrics.get('variable_robustness', 0.91),
              result.robustness_metrics.get('noise_robustness', 0.82)]
    
    bars = ax5.bar(metrics, values, color=['lightcoral', 'lightblue', 'lightgreen', 
                                          'yellow', 'orange', 'pink'])
    ax5.set_ylabel("Score")
    ax5.set_title("Robustness Metrics")
    ax5.set_ylim(0, 1.0)
    
    # Add value labels
    for bar, value in zip(bars, values):
        ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{value:.2f}', ha='center', va='bottom', fontsize=9)
    
    # 6. Component type breakdown
    ax6 = fig.add_subplot(gs[2, 2])
    
    type_counts = {}
    for comp in result.circuit_components:
        type_counts[comp.component_type] = type_counts.get(comp.component_type, 0) + 1
    
    wedges, texts, autotexts = ax6.pie(type_counts.values(), labels=type_counts.keys(), 
                                      autopct='%1.0f%%', startangle=90,
                                      colors=['lightcoral', 'lightblue', 'lightgreen'])
    ax6.set_title("Component Types")
    
    plt.suptitle("IOI Causal Circuit Discovery Results\n"
                f"Found {len(result.circuit_components)} components with "
                f"{result.robustness_metrics['robustness_score']:.0%} robustness", 
                fontsize=16, fontweight='bold')
    
    plt.savefig("demo_causal_ioi_comprehensive.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print("ðŸ“Š Demo visualization saved to demo_causal_ioi_comprehensive.png")

if __name__ == "__main__":
    result = create_demo_results()
    print("\nâœ… Demo results creation complete!")
    print("\nFiles generated:")
    print("  ðŸ“„ demo_causal_ioi_results.json - Detailed results")
    print("  ðŸ“Š demo_causal_ioi_comprehensive.png - Comprehensive visualization")