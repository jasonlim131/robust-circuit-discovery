{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962d20e1",
   "metadata": {},
   "source": [
    "### Benchmark Creation\n",
    "- logic operators: ==, !=, or, and\n",
    "- arity of 3: a, b, c unique boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CFG(OrderedDict):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(map(lambda s: s.replace(' ', '').split('->'), args))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join('{} -> {}'.format(k, v) for k, v in self.items())\n",
    "\n",
    "    def getProductions(self, symbol):\n",
    "        return self[symbol].split('|')\n",
    "\n",
    "# Depth-first walk through tree, selecting random productions\n",
    "def generateSentence(cfg, start='S'):\n",
    "    string = []\n",
    "    def dfs(root):\n",
    "        local_str = ''\n",
    "        prod = random.choice(cfg.getProductions(root))\n",
    "        for char in prod:\n",
    "            if char in cfg:\n",
    "                result = dfs(char)\n",
    "                if result:\n",
    "                    string.append(result)\n",
    "            else:\n",
    "                local_str += char\n",
    "        return local_str\n",
    "\n",
    "    dfs(start)\n",
    "    return ' '.join(string)\n",
    "\n",
    "# Example CFG found online\n",
    "L = [\n",
    "    'S -> CLAUSES',\n",
    "    'CLAUSES -> CLAUSE CONJ CLAUSE',\n",
    "    'CLAUSE -> LPR VAR EQ VAR RPR',\n",
    "    'CONJ -> \"and\" | \"or\"',\n",
    "    'EQ -> \"==\" | \"!=\"',\n",
    "    'VAR -> \"a\" | \"b\" | \"c\"',\n",
    "    'LPR -> \"(\"',\n",
    "    'RPR -> \")\"',\n",
    "]\n",
    "\n",
    "# Replacing variable names for simpler parsing\n",
    "table = OrderedDict([\n",
    "    ('CLAUSES', 'A'),\n",
    "    ('CLAUSE',  'B'),\n",
    "    ('CONJ',    'C'),\n",
    "    ('EQ',      'D'),\n",
    "    ('VAR',     'E'),\n",
    "    ('LPR',     'F'),\n",
    "    ('RPR',     'G')\n",
    "])\n",
    "\n",
    "conj_re = re.compile(r\"\"\"\n",
    "    ^\n",
    "    \\s*\n",
    "    \\(\n",
    "    \\s*(\\w+?)\\s*(?:==|!=)\\s*(\\w+?)\\s*\n",
    "    \\)\n",
    "    \\s*$\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d653bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = True\n",
    "if not SKIP:\n",
    "    for i in range(len(L)):\n",
    "        L[i] = L[i].replace('\\\"', '')\n",
    "        for key in table:\n",
    "            L[i] = L[i].replace(key, table[key])\n",
    "\n",
    "    cfg = CFG(*L)\n",
    "    primitive_clauses = set([])\n",
    "    equivalent_clauses = set([])\n",
    "    for _ in range(10000): # 10000 will get you all the programs.\n",
    "        clause = generateSentence(cfg)\n",
    "        if \"a == a\" in clause or \\\n",
    "            \"a != a\" in clause or \\\n",
    "            \"b == b\" in clause or \\\n",
    "            \"b != b\" in clause or \\\n",
    "            \"c == c\" in clause or \\\n",
    "            \"c != c\" in clause:\n",
    "            continue\n",
    "\n",
    "        if \"and\" in clause and \\\n",
    "            clause.split(\" and \")[0] == clause.split(\" and \")[1]:\n",
    "            continue\n",
    "        if \"or\" in clause and \\\n",
    "            clause.split(\" or \")[0] == clause.split(\" or \")[1]:\n",
    "            continue\n",
    "\n",
    "        if \"and\" in clause:\n",
    "            variables = set([])\n",
    "            for c in clause.split(\" and \"):\n",
    "                if \"==\" in c:\n",
    "                    for t in c.strip(\"() \").split(\" == \"):\n",
    "                        variables.add(t)\n",
    "                elif \"!=\" in c:\n",
    "                    for t in c.strip(\"() \").split(\" != \"):\n",
    "                        variables.add(t)\n",
    "            if len(variables) < 3:\n",
    "                continue\n",
    "\n",
    "            left = sorted(clause.split(\" and \")[0])\n",
    "            right = sorted(clause.split(\" and \")[1])\n",
    "\n",
    "            if (\"and\", tuple(left), tuple(right)) in equivalent_clauses or \\\n",
    "                (\"and\", tuple(right), tuple(left)) in equivalent_clauses:\n",
    "                continue\n",
    "            else:\n",
    "                equivalent_clauses.add((\"and\", tuple(left), tuple(right)))\n",
    "                equivalent_clauses.add((\"and\", tuple(right), tuple(left)))\n",
    "\n",
    "        if \"or\" in clause:\n",
    "            variables = set([])\n",
    "            for c in clause.split(\" or \"):\n",
    "                if \"==\" in c:\n",
    "                    for t in c.strip(\"() \").split(\" == \"):\n",
    "                        variables.add(t)\n",
    "                elif \"!=\" in c:\n",
    "                    for t in c.strip(\"() \").split(\" != \"):\n",
    "                        variables.add(t)\n",
    "            if len(variables) < 3:\n",
    "                continue\n",
    "\n",
    "            if (\"or\", tuple(left), tuple(right)) in equivalent_clauses or \\\n",
    "                (\"or\", tuple(right), tuple(left)) in equivalent_clauses:\n",
    "                continue\n",
    "            else:\n",
    "                equivalent_clauses.add((\"or\", tuple(left), tuple(right)))\n",
    "                equivalent_clauses.add((\"or\", tuple(right), tuple(left)))\n",
    "\n",
    "        primitive_clauses.add(clause)\n",
    "\n",
    "\n",
    "    primitive_clauses = list(primitive_clauses)\n",
    "    random.shuffle(primitive_clauses)\n",
    "    training_clauses = primitive_clauses[:20]\n",
    "    eval_clauses = primitive_clauses[20:]\n",
    "    pickle.dump(primitive_clauses, open(\"./cfg_all.pkl\", 'wb'))\n",
    "    pickle.dump(training_clauses, open(\"./cfg_train.pkl\", 'wb'))\n",
    "    pickle.dump(eval_clauses, open(\"./cfg_test.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6915748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(clauses):\n",
    "    conjs = re.split(r\"\\s*(?:and|or)\\s*\", clauses)\n",
    "    data = []\n",
    "    for conj in conjs:\n",
    "        if conj_re.search(conj):\n",
    "            LVAR, RVAR = conj_re.search(conj).groups()\n",
    "            EQ = \"==\" if \"==\" in conj else \"!=\"\n",
    "            d = {\n",
    "                \"L\" : LVAR,\n",
    "                \"R\" : RVAR,\n",
    "                \"EQ\" : EQ\n",
    "            }\n",
    "            data += [d]\n",
    "    return data\n",
    "\n",
    "def sample_demonstration_for_clauses(\n",
    "    clauses,\n",
    "    vocab,\n",
    "    final_value=None\n",
    "):\n",
    "    if final_value == None:\n",
    "        final_value = random.choice([True, False])\n",
    "\n",
    "    if \"and\" in clauses:\n",
    "        data = parse(clauses)\n",
    "        if final_value == True:\n",
    "            data[0][\"VAL\"] = True\n",
    "            data[1][\"VAL\"] = data[0][\"VAL\"]\n",
    "        else:\n",
    "            data[0][\"VAL\"] = True if random.random() >= 0.5 else False\n",
    "            data[1][\"VAL\"] = not data[0][\"VAL\"]\n",
    "    elif \"or\" in clauses:\n",
    "        data = parse(clauses)\n",
    "        if final_value:\n",
    "            data[0][\"VAL\"] = True if random.random() >= 0.5 else False\n",
    "            data[1][\"VAL\"] = random.choice([True, False]) if data[0][\"VAL\"] else True\n",
    "        else:\n",
    "            data[0][\"VAL\"] = False\n",
    "            data[1][\"VAL\"] = data[0][\"VAL\"]\n",
    "    else:\n",
    "        data = parse(clauses)\n",
    "        data[0][\"VAL\"] = final_value\n",
    "    \n",
    "    value_assignment = {}\n",
    "    for d in data:\n",
    "        if (d[\"EQ\"] == \"==\" and d[\"VAL\"] == True) or \\\n",
    "                (d[\"EQ\"] == \"!=\" and d[\"VAL\"] == False):\n",
    "            if d['L'] in value_assignment:\n",
    "                value_assignment[d['R']] = value_assignment[d['L']]\n",
    "            elif d['R'] in value_assignment:\n",
    "                value_assignment[d['L']] = value_assignment[d['R']]\n",
    "            else:\n",
    "                value_assignment[d['L']] = value_assignment[d['L']] if d['L'] in value_assignment else random.choice(list(vocab))\n",
    "                value_assignment[d['R']] = value_assignment[d['L']]\n",
    "                vocab -= {value_assignment[d['L']]}\n",
    "        elif (d[\"EQ\"] == \"==\" and d[\"VAL\"] == False) or \\\n",
    "                (d[\"EQ\"] == \"!=\" and d[\"VAL\"] == True):\n",
    "            if d['L'] in value_assignment:\n",
    "                value_assignment[d['R']] = random.choice(list(vocab))\n",
    "                assert value_assignment[d['R']] != value_assignment[d['L']]\n",
    "                vocab -= {value_assignment[d['R']]}\n",
    "            elif d['R'] in value_assignment:\n",
    "                value_assignment[d['L']] = random.choice(list(vocab))\n",
    "                assert value_assignment[d['L']] != value_assignment[d['R']]\n",
    "                vocab -= {value_assignment[d['L']]}\n",
    "            else:\n",
    "                value_assignment[d['L']] = random.choice(list(vocab))\n",
    "                vocab -= {value_assignment[d['L']]}\n",
    "                value_assignment[d['R']] = random.choice(list(vocab))\n",
    "                vocab -= {value_assignment[d['R']]}\n",
    "    \n",
    "    for d in data:\n",
    "        if (d[\"EQ\"] == \"==\" and d[\"VAL\"] == True) or \\\n",
    "                (d[\"EQ\"] == \"!=\" and d[\"VAL\"] == False):\n",
    "            assert value_assignment[d['L']] == value_assignment[d['R']]\n",
    "        elif (d[\"EQ\"] == \"==\" and d[\"VAL\"] == False) or \\\n",
    "                (d[\"EQ\"] == \"!=\" and d[\"VAL\"] == True):\n",
    "            assert value_assignment[d['L']] != value_assignment[d['R']]\n",
    "    \n",
    "    if \"and\" in clauses:\n",
    "        assert final_value == (data[0][\"VAL\"] and data[1][\"VAL\"])\n",
    "    elif \"or\" in clauses:\n",
    "        assert final_value == (data[0][\"VAL\"] or data[1][\"VAL\"])\n",
    "        \n",
    "    return value_assignment\n",
    "    # we need to assert check\n",
    "\n",
    "def sample_demonstrations_for_clauses(\n",
    "    clauses,\n",
    "    vocab,\n",
    "    final_values,\n",
    "):\n",
    "    demos = []\n",
    "    for i in range(len(final_values)):\n",
    "        demo = sample_demonstration_for_clauses(\n",
    "            clauses, vocab, final_values[i]\n",
    "        )\n",
    "        demo['clause'] = clauses\n",
    "        demo['output'] = final_values[i]\n",
    "        demos += [demo]\n",
    "    return demos\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a865e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "n_training_examples = 20000\n",
    "n_eval_examples = 1000\n",
    "n_test_examples = 1000\n",
    "n_training_program = 15\n",
    "n_fewshot = 6\n",
    "\n",
    "#################\n",
    "#\n",
    "# DO NOT CHANGE\n",
    "#\n",
    "#################\n",
    "FALSE_TOKEN_ID = 0\n",
    "TRUE_TOKEN_ID = 1\n",
    "INPUT_PREFIX_TOKEN_ID = 2\n",
    "OUTPUT_PREFIX_TOKEN_ID = 3\n",
    "SEPARATOR_TOKEN_ID = 4\n",
    "PADDING_TOKEN_ID = 5\n",
    "BOS_TOKEN_ID = 6\n",
    "EOS_TOKEN_ID = 7\n",
    "\n",
    "vocab = set([i for i in range(10, 50257)]) # reserve the first 10 for special tokens.\n",
    "n_examples = n_fewshot + 1\n",
    "training_clauses = pickle.load(open(\"./cfg_train.pkl\", 'rb'))\n",
    "eval_clauses = pickle.load(open(\"./cfg_test.pkl\", 'rb'))\n",
    "if n_training_program is not None:\n",
    "    training_clauses = random.sample(training_clauses, k=n_training_program)\n",
    "\n",
    "all_train_input_ids = []\n",
    "all_train_output_ids = []\n",
    "all_train_clauses = []\n",
    "for i in tqdm(range(n_training_examples)):\n",
    "    clauses = random.choice(training_clauses)\n",
    "    demostrations = sample_demonstrations_for_clauses(\n",
    "        clauses,\n",
    "        copy.deepcopy(vocab),\n",
    "        final_values=[random.choice([True, False]) for i in range(n_examples)]\n",
    "    )\n",
    "    \n",
    "    # listify\n",
    "    input_ids = [BOS_TOKEN_ID]\n",
    "    output_ids = [BOS_TOKEN_ID]\n",
    "    for d in demostrations:\n",
    "        output = FALSE_TOKEN_ID if d['output'] == False else TRUE_TOKEN_ID\n",
    "        input_ids += [INPUT_PREFIX_TOKEN_ID, d['a'], d['b'], d['c'], OUTPUT_PREFIX_TOKEN_ID, output, SEPARATOR_TOKEN_ID]\n",
    "        output_ids += [-100, -100, -100, -100, -100, output, -100]\n",
    "        assert len(input_ids) == len(output_ids)\n",
    "    input_ids += [EOS_TOKEN_ID]\n",
    "    output_ids += [EOS_TOKEN_ID]\n",
    "    all_train_input_ids += [input_ids]\n",
    "    all_train_output_ids += [output_ids]\n",
    "    all_train_clauses += [clauses]\n",
    "    \n",
    "all_eval_input_ids = []\n",
    "all_eval_output_ids = []\n",
    "all_eval_clauses = []\n",
    "for i in tqdm(range(n_eval_examples)):\n",
    "    clauses = random.choice(training_clauses)\n",
    "    demostrations = sample_demonstrations_for_clauses(\n",
    "        clauses,\n",
    "        copy.deepcopy(vocab),\n",
    "        final_values=[random.choice([True, False]) for i in range(n_examples)]\n",
    "    )\n",
    "    \n",
    "    # listify\n",
    "    input_ids = [BOS_TOKEN_ID]\n",
    "    output_ids = [BOS_TOKEN_ID]\n",
    "    for d in demostrations:\n",
    "        output = FALSE_TOKEN_ID if d['output'] == False else TRUE_TOKEN_ID\n",
    "        input_ids += [INPUT_PREFIX_TOKEN_ID, d['a'], d['b'], d['c'], OUTPUT_PREFIX_TOKEN_ID, output, SEPARATOR_TOKEN_ID]\n",
    "        output_ids += [-100, -100, -100, -100, -100, output, -100]\n",
    "        assert len(input_ids) == len(output_ids)\n",
    "    input_ids += [EOS_TOKEN_ID]\n",
    "    output_ids += [EOS_TOKEN_ID]\n",
    "    all_eval_input_ids += [input_ids]\n",
    "    all_eval_output_ids += [output_ids]\n",
    "    all_eval_clauses += [clauses]\n",
    "    \n",
    "train_data = {\n",
    "    \"input_ids\" : all_train_input_ids,\n",
    "    \"output_ids\" : all_train_output_ids,\n",
    "    \"clauses\" : all_train_clauses,\n",
    "}\n",
    "dev_data = {\n",
    "    \"input_ids\" : all_eval_input_ids,\n",
    "    \"output_ids\" : all_eval_output_ids,\n",
    "    \"clauses\" : all_eval_clauses,\n",
    "}\n",
    "pickle.dump(train_data, open(f\"./train_data.n_rule.{n_training_program}.n_shot.{n_fewshot}.pkl\", 'wb'))\n",
    "pickle.dump(dev_data, open(f\"./dev_data.n_rule.{n_training_program}.n_shot.{n_fewshot}.pkl\", 'wb'))\n",
    "\n",
    "all_test_input_ids = []\n",
    "all_test_output_ids = []\n",
    "all_test_clauses = []\n",
    "for i in tqdm(range(n_test_examples)):\n",
    "    clauses = random.choice(eval_clauses)\n",
    "    demostrations = sample_demonstrations_for_clauses(\n",
    "        clauses,\n",
    "        copy.deepcopy(vocab),\n",
    "        final_values=[random.choice([True, False]) for i in range(n_examples)]\n",
    "    )\n",
    "    \n",
    "    # listify\n",
    "    input_ids = [BOS_TOKEN_ID]\n",
    "    output_ids = [BOS_TOKEN_ID]\n",
    "    for d in demostrations:\n",
    "        output = FALSE_TOKEN_ID if d['output'] == False else TRUE_TOKEN_ID\n",
    "        input_ids += [INPUT_PREFIX_TOKEN_ID, d['a'], d['b'], d['c'], OUTPUT_PREFIX_TOKEN_ID, output, SEPARATOR_TOKEN_ID]\n",
    "        output_ids += [-100, -100, -100, -100, -100, output, -100]\n",
    "        assert len(input_ids) == len(output_ids)\n",
    "    input_ids += [EOS_TOKEN_ID]\n",
    "    output_ids += [EOS_TOKEN_ID]\n",
    "    all_test_input_ids += [input_ids]\n",
    "    all_test_output_ids += [output_ids]\n",
    "    all_test_clauses += [clauses]\n",
    "    \n",
    "test_data = {\n",
    "    \"input_ids\" : all_test_input_ids,\n",
    "    \"output_ids\" : all_test_output_ids,\n",
    "    \"clauses\" : all_test_clauses,\n",
    "}\n",
    "pickle.dump(test_data, open(f\"./test_data.n_rule.{n_training_program}.n_shot.{n_fewshot}.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
