{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Causal Abstraction Analysis with Distributed Alignment Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Atticus Geiger\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. [The hierarchical equality task](#The-hierarchical-equality-task)\n",
    "    1. [An Algorithm that Solves the Equality Task](#An-Algorithm-that-Solves-the-Equality-Task)\n",
    "        1. [The algorithm with no intervention](#The-algorithm-with-no-intervention)\n",
    "        1. [The algorithm with an intervention](#The-algorithm-with-an-intervention)\n",
    "        1. [The algorithm with an interchange intervention](#The-algorithm-with-an-interchange-intervention)\n",
    "    1. [Hand Crafting an MLP to Solve Hierarchical Equality](#Hand-Crafting-an-MLP-to-Solve-Hierarchical-Equality)        \n",
    "    1. [Training an MLP to Solve Hierarchical Equality](#Training-an-MLP-to-Solve-Hierarchical-Equality)\n",
    "1. [Causal abstraction Analysis](#Causal-abstraction)\n",
    "    1. [Basic intervention: zeroing out part of a hidden layer](#Basic-intervention:-zeroing-out-part-of-a-hidden-layer)\n",
    "    1. [An interchange intervention](#An-interchange-intervention)\n",
    "    1. [Alignment](#Alignment)\n",
    "    1. [Evaluating an Alignment](#Evaluation)\n",
    "1. [Interchange Intervention Training (IIT)](#Interchange-Intervention-Training-(IIT))\n",
    "1. [Distributed Alignment Search (DAS)](#Distributed-Alignment-Search-(DAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "This notebook is a hands-on introduction to __causal abstraction analysis__ using __distributed alignment search__ with neural networks.\n",
    "\n",
    "In causal abstraction analysis, we assess whether trained models conform to high-level causal models that we specify, not just in terms of their inputâ€“output behavior, but also in terms of their internal dynamics. The core technique is the __interchange intervention__, in which a causal model is provided an input and then intermediate variables are fixed to take on the values they would have for a second input.\n",
    "\n",
    "To motivate and illustrate these concepts, we're going to focus on a hierarchical equality task, building on work by [Geiger, Carstensen, Frank, and Potts (2020)](https://arxiv.org/abs/2006.07968)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'highlevel_models.causal_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18836\\2709881787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhighlevel_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcausal_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCausalModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'highlevel_models.causal_model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from highlevel_models.causal_model import CausalModel\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from models.mlp.modelings_mlp import MLPConfig\n",
    "from models.mlp.modelings_alignable_mlp import create_mlp_classifier\n",
    "from models.configuration_alignable_model import AlignableRepresentationConfig, AlignableConfig\n",
    "from models.interventions import VanillaIntervention, LowRankRotatedSpaceIntervention, RotatedIntervention\n",
    "from models.alignable_base import AlignableModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "embedding_dim = 2\n",
    "number_of_entities = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The hierarchical equality task\n",
    "\n",
    "This section builds on results presented in [Geiger, Carstensen, Frank, and Potts (2020)](https://arxiv.org/abs/2006.07968). We will use a hierarchical equality task ([Premack 1983](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7DF6F2D22838F7546AF7279679F3571D/S0140525X00015077a.pdf/div-class-title-the-codes-of-man-and-beasts-div.pdf)) to present interchange intervention training (IIT). \n",
    "\n",
    "We define the hierarchical equality task as follows: The input is two pairs of objects and the output is **True** if both pairs contain the same object or if both pairs contain different objects and **False** otherwise.  For example, `AABB` and `ABCD` are both labeled **True**, while `ABCC` and `BBCD` are both labeled **False**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Algorithm that Solves the Equality Task\n",
    "\n",
    "Let $\\mathcal{A}$ be the simple tree-structured algorithm that solves this task by applying a simple equality relation three times: Compute whether the first two inputs are equal, compute whether the second two inputs are equal, then compute whether the truth-valued outputs of these first two computations are equal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a Python implementation of $\\mathcal{A}$ that supports the interventions we'll want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randvec(n=50, lower=-1, upper=1):\n",
    "    return np.array([random.uniform(lower, upper) for i in range(n)])\n",
    "\n",
    "variables =  [\"W\", \"X\", \"Y\", \"Z\", \"WX\", \"YZ\", \"O\"]\n",
    "\n",
    "reps = [randvec(embedding_dim, lower=-1, upper=1) for _ in range(number_of_entities)]\n",
    "values = {variable:reps for variable in [\"W\",\"X\", \"Y\", \"Z\"]}\n",
    "values[\"WX\"] = [True, False]\n",
    "values[\"YZ\"] = [True, False]\n",
    "values[\"O\"] = [True, False]\n",
    "\n",
    "parents = {\"W\":[],\"X\":[], \"Y\":[], \"Z\":[], \n",
    "           \"WX\":[\"W\", \"X\"], \"YZ\":[\"Y\", \"Z\"], \n",
    "           \"O\":[\"WX\", \"YZ\"]}\n",
    "\n",
    "def FILLER():\n",
    "    return reps[0]\n",
    "\n",
    "functions = {\"W\":FILLER,\"X\":FILLER, \"Y\":FILLER, \"Z\":FILLER, \n",
    "             \"WX\": lambda x,y: np.array_equal(x,y), \n",
    "             \"YZ\":lambda x,y: np.array_equal(x,y), \n",
    "             \"O\": lambda x,y: x==y}\n",
    "\n",
    "pos = {\"W\":(0.2,0),\"X\":(1,0.1), \"Y\":(2,0.2), \"Z\":(2.8,0), \n",
    "           \"WX\":(1,2), \"YZ\":(2,2), \n",
    "           \"O\":(1.5,3)}\n",
    "\n",
    "equiv_classes = {}\n",
    "\n",
    "equality_model = CausalModel(variables, values, parents, functions, pos = pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a visual depiction of the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equality_model.print_structure()\n",
    "print(\"Timesteps:\", equality_model.timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with no intervention\n",
    "\n",
    "Let's first observe the behavior of the algorithm when we provide the input `BBCD` with no interventions. Here is a visual depiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = equality_model.run_forward({\"W\":reps[0], \"X\":reps[0], \"Y\":reps[1], \"Z\":reps[3]})\n",
    "print(\"No intervention:\\n\", setting, \"\\n\")\n",
    "equality_model.print_setting(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an intervention\n",
    "\n",
    "Let's now see the behavior of the algorithm when we provide the input `BBCD` with an intervention setting **WX** to **False**. First, a visual depiction:\n",
    "\n",
    "<img src=\"fig/IIT/PremackIntervention.png\" width=\"500\"/>\n",
    "\n",
    "And then the same computation with `compute_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intervention setting WX to TRUE:\\n\", )\n",
    "equality_model.print_setting(equality_model.run_forward({\"W\":reps[0], \"X\":reps[0], \"Y\":reps[1], \"Z\":reps[3], \"WX\":False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, in this example, even though the left two inputs are not the same, the intervention has changed the intermediate prediction for those two inputs from **False** to **True**, and thus the algorithm outputs **True**, since its output is determined by **WX** and **YZ**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an interchange intervention\n",
    "\n",
    "Finally, let's observe the behavior of the algorithm when we provide the base input `BBCD` with an intervention setting **WX** to be the value it would be for the source input `ABCC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = {\"W\":reps[0], \"X\":reps[0], \"Y\":reps[1], \"Z\":reps[3]}\n",
    "source = {\"W\":reps[0], \"X\":reps[1], \"Y\":reps[2], \"Z\":reps[2]}\n",
    "setting = equality_model.run_interchange(base, {\"WX\":source})\n",
    "equality_model.print_setting(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Crafting an MLP to Solve Hierarchical Equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2048*16\n",
    "\n",
    "X, y = equality_model.generate_factual_dataset(n_examples,equality_model.sample_input_tree_balanced)\n",
    "\n",
    "X = X.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MLPConfig(h_dim=embedding_dim*4,\n",
    "          activation_function = \"relu\",\n",
    "          n_layer = 2,\n",
    "          n_labels = 2,\n",
    "          pdrop = 0.0\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, tokenizer, handcrafted = create_mlp_classifier(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer of our handcrafted model computes:\n",
    "\n",
    "$ReLU(W_1[\\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{d}]) = [max(\\mathbf{a}-\\mathbf{b}, 0), max(\\mathbf{b}-\\mathbf{a}, 0), max(\\mathbf{c}-\\mathbf{d}, 0), max(\\mathbf{d}-\\mathbf{c}, 0)]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = [[ 1,  0, -1,  0,  0,  0,  0,  0],\n",
    "      [ 0,  1,  0, -1,  0,  0,  0,  0],\n",
    "      [-1,  0,  1,  0,  0,  0,  0,  0],\n",
    "      [ 0, -1,  0,  1,  0,  0,  0,  0],\n",
    "      [ 0,  0,  0,  0,  1,  0, -1,  0],\n",
    "      [ 0,  0,  0,  0,  0,  1,  0, -1],\n",
    "      [ 0,  0,  0,  0, -1,  0,  1,  0],\n",
    "      [ 0,  0,  0,  0,  0, -1,  0,  1]]\n",
    "handcrafted.mlp.h[0].ff1.weight = torch.nn.Parameter(torch.FloatTensor(W1))\n",
    "handcrafted.mlp.h[0].ff1.bias = torch.nn.Parameter(torch.FloatTensor([0,0,0,0,0,0,0,0]))\n",
    "handcrafted.mlp.h[0].ff2.weight = torch.nn.Parameter(torch.eye(embedding_dim*4))\n",
    "handcrafted.mlp.h[0].ff2.bias = torch.nn.Parameter(torch.FloatTensor([0,0,0,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer of our handcrafted model computes:\n",
    "\n",
    "$ReLU(W_2ReLU(W_1[\\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{d}])) = [|\\mathbf{a}-\\mathbf{b}| - |\\mathbf{c}-\\mathbf{d}|, |\\mathbf{c}-\\mathbf{d}|-|\\mathbf{a}-\\mathbf{b}|, |\\mathbf{a}-\\mathbf{b}|, |\\mathbf{c}-\\mathbf{d}|,0,0,0,0]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = [[ 1,-1, 0, 1, 0, 0, 0, 0],\n",
    "      [ 1,-1, 0, 1, 0, 0, 0, 0],\n",
    "      [ 1,-1, 0, 1, 0, 0, 0, 0],\n",
    "      [ 1,-1, 0, 1, 0, 0, 0, 0],\n",
    "      [-1, 1, 1, 0, 0, 0, 0, 0],\n",
    "      [-1, 1, 1, 0, 0, 0, 0, 0],\n",
    "      [-1, 1, 1, 0, 0, 0, 0, 0],\n",
    "      [-1, 1, 1, 0, 0, 0, 0, 0]]\n",
    "handcrafted.mlp.h[1].ff1.weight = torch.nn.Parameter(torch.FloatTensor(W2).transpose(0,1))\n",
    "handcrafted.mlp.h[1].ff1.bias = torch.nn.Parameter(torch.FloatTensor([0,0,0,0,0,0,0,0]))\n",
    "handcrafted.mlp.h[1].ff2.weight = torch.nn.Parameter(torch.eye(embedding_dim*4))\n",
    "handcrafted.mlp.h[1].ff2.bias = torch.nn.Parameter(torch.FloatTensor([0,0,0,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third layer of our handcrafted model computes the logits:\n",
    "\n",
    "$W_3 ReLU(W_2ReLU(W_1[\\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{d}])) = [||\\mathbf{a}-\\mathbf{b}| - |\\mathbf{c}-\\mathbf{d}|| -0.999999|\\mathbf{a}-\\mathbf{b}|-0.999999|\\mathbf{c}-\\mathbf{d}|, 0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = [[        1, 0],\n",
    "      [        1, 0],\n",
    "      [-0.999999, 0],\n",
    "      [-0.999999, 0],\n",
    "      [        0, 0],\n",
    "      [        0, 0],\n",
    "      [        0, 0],\n",
    "      [        0, 0]]\n",
    "handcrafted.score.weight = torch.nn.Parameter(torch.FloatTensor(W3).transpose(0,1))\n",
    "handcrafted.score.bias = torch.nn.Parameter(torch.FloatTensor([0,0.00000000000001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = handcrafted.forward(inputs_embeds=X)\n",
    "\n",
    "print(\"Train Results\")\n",
    "print(classification_report(y, preds[0].squeeze(1).argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal abstraction\n",
    "\n",
    "The formal theory of **causal abstraction** describes the conditions that must hold for the high-level tree structured algorithm to be a **simplified and faithful description** of the neural network. \n",
    "\n",
    "In essence: an high-level model is a causal abstraction of a neural network if and only if for all base and source inputs, the algorithm and network provides the same output, for some alignment between these two models.\n",
    "\n",
    "Below, we define an alignment between the neural network and the algorithm and a function to compute the **interchange intervention accuracy** (II accuracy) for a high-level variable: the percentage of aligned interchange interventions that the network and algorithm produce the same output on. When the II accuracy is 100%, the causal abstraction relation holds between the network and a simplified version of the algorithm where only one high-level variable exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignable_config = AlignableConfig(\n",
    "        alignable_model_type=type(handcrafted),\n",
    "        alignable_representations=[\n",
    "            AlignableRepresentationConfig(\n",
    "                0,             # layer\n",
    "                \"block_output\", # intervention type\n",
    "                \"pos\",             # intervention unit\n",
    "                1,                  # max number of unit\n",
    "                subspace_partition = [[0,4],[4,8]],\n",
    "             intervention_link_key=0 # create sym link across interventions\n",
    "            ),\n",
    "            AlignableRepresentationConfig(\n",
    "                0,             # layer\n",
    "                \"block_output\", # intervention type\n",
    "                \"pos\",             # intervention unit\n",
    "                1,                  # max number of unit\n",
    "                subspace_partition = [[0,4],[4,8]],\n",
    "             intervention_link_key=0 # create sym link across interventions\n",
    "            ),\n",
    "        ],\n",
    "        alignable_interventions_type=RotatedIntervention,\n",
    "    )\n",
    "alignable_handcrafted = AlignableModel(alignable_config, handcrafted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a counterfactual equality dataset that includes interchange intervention examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervention_id(intervention):\n",
    "    if \"WX\" in intervention and \"YZ\" in intervention:\n",
    "        return WXYZ\n",
    "    if \"WX\" in intervention:\n",
    "        return WX\n",
    "    if \"YZ\" in intervention:\n",
    "        return YZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 2048*16\n",
    "batch_size = 16\n",
    "WX = 0\n",
    "YZ = 1\n",
    "WXYZ = 2\n",
    "dataset = equality_model.generate_counterfactual_dataset(data_size,\n",
    "                                                        intervention_id,\n",
    "                                                        16,\n",
    "                                                        device = \"cuda:0\",\n",
    "                                                        sampler=equality_model.sample_input_tree_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset[0][\"input_ids\"])\n",
    "print(dataset[0][\"source_input_ids\"])\n",
    "print(dataset[0][\"labels\"])\n",
    "print(dataset[0][\"base_labels\"])\n",
    "print(dataset[0][\"intervention_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has the following components:\n",
    "\n",
    "* `X_base_train`: a regular set of train examples\n",
    "* `y_base_train`: a regular set of train labels\n",
    "* `X_sources_train`: a list additional train sets (here, a singleton list of them) for counterfactuals\n",
    "* `y_IIT_train`: a list of labels for the examples in `X_sources_train`.\n",
    "* `interventions`: a list of intervention sites (here, all `0` corresponding to our key for \"V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handcrafted.to(\"cuda:0\")\n",
    "for parameter in alignable_handcrafted.get_trainable_parameters():\n",
    "    parameter.to(\"cuda:0\")\n",
    "preds = []\n",
    "for batch in DataLoader(dataset, batch_size):\n",
    "    batch[\"input_ids\"] = batch[\"input_ids\"].unsqueeze(1)    \n",
    "    batch[\"source_input_ids\"] = batch[\"source_input_ids\"].unsqueeze(2)    \n",
    "    if batch[\"intervention_id\"][0] == 2:\n",
    "        _, counterfactual_outputs = alignable_handcrafted(\n",
    "                {\"inputs_embeds\":batch[\"input_ids\"]},\n",
    "                [{\"inputs_embeds\":batch[\"source_input_ids\"][:, 0]}, \n",
    "                 {\"inputs_embeds\":batch[\"source_input_ids\"][:,1]}],\n",
    "                {\"sources->base\": ([[[0]]*batch_size, [[0]]*batch_size], [[[0]]*batch_size, [[0]]*batch_size])},\n",
    "            subspaces=[[[0]]*batch_size, [[1]]*batch_size]\n",
    "            )\n",
    "    elif batch[\"intervention_id\"][0] == 1:\n",
    "        _, counterfactual_outputs = alignable_handcrafted(\n",
    "                {\"inputs_embeds\":batch[\"input_ids\"]},\n",
    "                [{\"inputs_embeds\":batch[\"source_input_ids\"][:,0]}, None],\n",
    "                {\"sources->base\": ([[[0]]*batch_size, None], [[[0]]*batch_size, None])},\n",
    "                subspaces=[[[0]]*batch_size, None]\n",
    "            )\n",
    "    elif batch[\"intervention_id\"][0] == 0:\n",
    "        _, counterfactual_outputs = alignable_handcrafted(\n",
    "                {\"inputs_embeds\":batch[\"input_ids\"]},\n",
    "                [None, {\"inputs_embeds\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([None, [[0]]*batch_size], [None, [[0]]*batch_size])},\n",
    "                subspaces=[None, [[1]]*batch_size]\n",
    "            )\n",
    "    preds.append(counterfactual_outputs)\n",
    "preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(torch.tensor([x[\"labels\"] for x in dataset]).cpu(), preds.argmax(1).cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an MLP to Solve Hierarchical Equality\n",
    "\n",
    "We've now seen how interventions work in our high-level causal model. We turn now to doing parallel work in our neural network, which will be a fully-connected feed-forward neural network with three hidden layers. The following code simply extends `TorchDeepNeuralClassifier` with a method `retrieve_activations` that supports interventions on PyTorch computation graphs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `iit` provides some dataset functions for equality learning. Here we define a simple an equality dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples in this dataset are 8-dimensional vectors: the concatenation of 4 2-dimensional vectors. Here's the first example with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label for this example is determined by whether the equality value for the first two inputs matches the equality value for the second two inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = torch.equal(\n",
    "    X[0][: embedding_dim],\n",
    "    X[0][embedding_dim: embedding_dim*2])\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = torch.equal(\n",
    "    X[0][embedding_dim*2: embedding_dim*3],\n",
    "    X[0][embedding_dim*3: ])\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(left == right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model does out-of-the-box on this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained = MLPClassifier(\n",
    "    hidden_dim=embedding_dim*4, \n",
    "    hidden_activation=torch.nn.ReLU(), \n",
    "    num_layers=2,\n",
    "    input_dim=embedding_dim*4,\n",
    "    input_len=4,\n",
    "    n_classes=2,\n",
    "    warm_start=True,\n",
    "    max_iter=100,\n",
    "    batch_size=64,\n",
    "    n_iter_no_change=10000,\n",
    "    shuffle_train=False,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trained.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network achieves near perfect performance on its train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trained.predict(X, device=\"cpu\")\n",
    "\n",
    "\n",
    "print(\"Train Results\")\n",
    "print(classification_report(y, preds.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it generalizes perfectly to a test set consisting of distinct vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables =  [\"W\", \"X\", \"Y\", \"Z\", \"WX\", \"YZ\", \"O\"]\n",
    "\n",
    "number_of__test_entities = 100\n",
    "\n",
    "reps = [tutorial_utils.randvec(embedding_dim).round(2)  for _ in range(number_of__test_entities)]\n",
    "values = {variable:reps for variable in [\"W\",\"X\", \"Y\", \"Z\"]}\n",
    "values[\"WX\"] = [True, False]\n",
    "values[\"YZ\"] = [True, False]\n",
    "values[\"O\"] = [True, False]\n",
    "\n",
    "parents = {\"W\":[],\"X\":[], \"Y\":[], \"Z\":[], \n",
    "           \"WX\":[\"W\", \"X\"], \"YZ\":[\"Y\", \"Z\"], \n",
    "           \"O\":[\"WX\", \"YZ\"]}\n",
    "\n",
    "def FILLER():\n",
    "    return reps[0]\n",
    "\n",
    "functions = {\"W\":FILLER,\"X\":FILLER, \"Y\":FILLER, \"Z\":FILLER, \n",
    "             \"WX\": lambda x,y: np.array_equal(x,y), \"YZ\":lambda x,y: np.array_equal(x,y), \n",
    "             \"O\": lambda x,y: x==y}\n",
    "\n",
    "pos = {\"W\":(0,0),\"X\":(1,0.1), \"Y\":(2,0.2), \"Z\":(3,0), \n",
    "           \"WX\":(1,2), \"YZ\":(2,2), \n",
    "           \"O\":(1.5,3)}\n",
    "\n",
    "test_equality_model = CausalModel(variables, values, parents, functions, pos = pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_equality_model.generate_factual_dataset(10000,equality_model.sample_input_tree_balanced)\n",
    "print(\"Test Results\")\n",
    "\n",
    "test_preds = trained.predict(X_test, device=\"cpu\")\n",
    "\n",
    "print(classification_report(y_test, test_preds.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = equality_model.generate_counterfactual_dataset(data_size,\n",
    "                                                        intervention_id,\n",
    "                                                        16,\n",
    "                                                        device = \"cuda:0\",\n",
    "                                                        sampler=equality_model.sample_input_tree_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it implement our high-level model of the problem, though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Alignment Search\n",
    "\n",
    "Interchange Intervention Training (IIT) is a method for training a neural network to conform to the causal structure of a high-level algorithm. Conceptually, it is a direct extension of the causal abstraction analysis we just performed, except instead of **evaluating** whether the neural network and algorithm produce the same outputs under aligned interchange interventions, we are now **training** the neural network to produce the output of the algorithm under aligned interchange interventions.\n",
    "\n",
    "IIT was developed by [Geiger\\*, Wu\\*, Lu\\*, Rozner, Kreiss, Icard, Goodman, and Potts (2021)](https://arxiv.org/abs/2112.00826), and it is used for model distillation [ Wu\\*, Geiger\\*, Rozner, Kreiss, Lu, Icard, Goodman, and Potts (2022)](https://arxiv.org/abs/2112.02505)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignable_config = AlignableConfig(\n",
    "    alignable_model_type=type(trained),\n",
    "    alignable_representations=[\n",
    "        AlignableRepresentationConfig(\n",
    "            0,             # layer\n",
    "            \"block_output\", # intervention type\n",
    "            \"pos\",    # intervention unit is now aligne with tokens\n",
    "            4,                 # max number of unit\n",
    "            alignable_low_rank_dimension = 4 * embedding_dim, # the full space\n",
    "            subspace_partition=[[0,2 * embedding_dim],[2 * embedding_dim,4 * embedding_dim]]      # binary partition with equal sizes\n",
    "        ),\n",
    "    ],\n",
    "    alignable_interventions_type=LowRankRotatedSpaceIntervention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignable = AlignableModel(alignable_config, trained)\n",
    "alignable.set_device(\"cuda\")\n",
    "alignable.disable_model_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = int(len(dataset) * 3)\n",
    "warm_up_steps = 0.1 * t_total\n",
    "optimizer_params = []\n",
    "for k, v in alignable.interventions.items():\n",
    "    optimizer_params += [{'params': v[0].rotate_layer.parameters()}]\n",
    "optimizer = torch.optim.Adam(\n",
    "    optimizer_params,\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_preds, eval_labels):\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for eval_pred, eval_label in zip(eval_preds, eval_labels):\n",
    "        actual_test_labels = eval_label[:, -1]\n",
    "        pred_test_labels = torch.argmax(eval_pred[:, -1], dim=-1)\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "    accuracy = round(correct_count/total_count, 2)\n",
    "    return {\"accuracy\" : accuracy}\n",
    "\n",
    "epochs = 2\n",
    "gradient_accumulation_steps = 4\n",
    "total_step = 0\n",
    "target_total_step = len(dataset) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignable.model.train() # train enables drop-off but no grads\n",
    "print(\"MLP trainable parameters: \", count_parameters(alignable.model))\n",
    "print(\"intervention trainable parameters: \", alignable.count_parameters())\n",
    "train_iterator = trange(\n",
    "    0, int(epochs), desc=\"Epoch\"\n",
    ")\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        DataLoader(dataset, batch_size), desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
    "    )\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        for k, v in batch.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(\"cuda\")\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "        if batch[\"intervention_id\"][0] == 2: \n",
    "            continue\n",
    "#             _, counterfactual_outputs = alignable(\n",
    "#                 {\"input_ids\":batch[\"input_ids\"]},\n",
    "#                 [{\"input_ids\":batch[\"source_input_ids\"][:, 0]}, \n",
    "#                  {\"input_ids\":batch[\"source_input_ids\"][:, 1]}],\n",
    "#                 {\"sources->base\": ([[[0,1,2,3]]*batch_size, [[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size, [[0,1,2,3]]*batch_size])},\n",
    "#                 None,\n",
    "#                 [[[0,1]]*batch_size]\n",
    "#             )\n",
    "        elif batch[\"intervention_id\"][0] ==1:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "                None,\n",
    "                [[[1]]*batch_size]\n",
    "            )\n",
    "        elif batch[\"intervention_id\"][0] ==0:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "                None,\n",
    "                [[[0]]*batch_size]\n",
    "            )\n",
    "        eval_metrics = compute_metrics(\n",
    "            [counterfactual_outputs], [batch['labels']]\n",
    "        )\n",
    "        \n",
    "        # loss and backprop\n",
    "        loss = alignable.model.loss(\n",
    "            counterfactual_outputs, batch[\"labels\"].squeeze().type(torch.LongTensor).to(\"cuda\")\n",
    "        )\n",
    "        loss_str = round(loss.item(), 2)\n",
    "        epoch_iterator.set_postfix({'loss': loss_str, 'acc': eval_metrics[\"accuracy\"]})\n",
    "        \n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        if total_step % gradient_accumulation_steps == 0:\n",
    "            if not (gradient_accumulation_steps > 1 and total_step == 0):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                alignable.set_zero_grad()\n",
    "    total_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_labels = []\n",
    "eval_preds = []\n",
    "with torch.no_grad():\n",
    "    epoch_iterator = tqdm(DataLoader(dataset, batch_size), desc=f\"Test\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        for k, v in batch.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(\"cuda\")\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "        if batch[\"intervention_id\"][0] == 2: \n",
    "            continue\n",
    "#             _, counterfactual_outputs = alignable(\n",
    "#                 {\"input_ids\":batch[\"input_ids\"]},\n",
    "#                 [{\"input_ids\":batch[\"source_input_ids\"][:, 0]}, \n",
    "#                  {\"input_ids\":batch[\"source_input_ids\"][:,1]}],\n",
    "#                 {\"sources->base\": ([[[0,1]]*batch_size, [[2,3]]*batch_size], [[[0,1]]*batch_size, [[2,3]]*batch_size])} \n",
    "#             )\n",
    "        elif batch[\"intervention_id\"][0] == 1:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "                None,\n",
    "                [[[1]]*batch_size]\n",
    "            )\n",
    "        elif batch[\"intervention_id\"][0] == 0:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "                None,\n",
    "                [[[0]]*batch_size]\n",
    "            )\n",
    "        eval_labels += [batch['labels']]\n",
    "        eval_preds += [torch.argmax(counterfactual_outputs,dim=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(torch.cat(eval_labels).cpu(), torch.cat(eval_preds).cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_labels = []\n",
    "eval_preds = []\n",
    "with torch.no_grad():\n",
    "    epoch_iterator = tqdm(DataLoader(test_dataset, batch_size), desc=f\"Test\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        for k, v in batch.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(\"cuda\")\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "        if batch[\"intervention_id\"][0] == 2: \n",
    "            continue\n",
    "#             _, counterfactual_outputs = alignable(\n",
    "#                 {\"input_ids\":batch[\"input_ids\"]},\n",
    "#                 [{\"input_ids\":batch[\"source_input_ids\"][:, 0]}, \n",
    "#                  {\"input_ids\":batch[\"source_input_ids\"][:,1]}],\n",
    "#                 {\"sources->base\": ([[[0,1]]*batch_size, [[2,3]]*batch_size], [[[0,1]]*batch_size, [[2,3]]*batch_size])} \n",
    "#             )\n",
    "        elif batch[\"intervention_id\"][0] ==1:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "            )\n",
    "        elif batch[\"intervention_id\"][0] ==0:\n",
    "            _, counterfactual_outputs = alignable(\n",
    "                {\"input_ids\":batch[\"input_ids\"]},\n",
    "                [{\"input_ids\":batch[\"source_input_ids\"][:,0]}],\n",
    "                {\"sources->base\": ([[[0,1,2,3]]*batch_size], [[[0,1,2,3]]*batch_size])},\n",
    "            )\n",
    "        eval_labels += [batch['labels']]\n",
    "        eval_preds += [torch.argmax(counterfactual_outputs,dim=1)]\n",
    "print(classification_report(torch.cat(eval_labels).cpu(), torch.cat(eval_preds).cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use find_alingment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_locations(example):\n",
    "    example[\"source_0->base.0.pos\"] = [0,1,2,3] # target the whole layer\n",
    "    example[\"source_0->base.1.pos\"] = [0,1,2,3] \n",
    "    example[\"source_1->base.0.pos\"] = [0,1,2,3] # target the whole layer\n",
    "    example[\"source_1->base.1.pos\"] = [0,1,2,3] \n",
    "    if example[\"intervention_id\"] == 0:\n",
    "        example[\"source_0->subspaces\"] = [[0]]\n",
    "    if example[\"intervention_id\"] == 1:\n",
    "        example[\"source_0->subspaces\"] = [[1]]   \n",
    "    if example[\"intervention_id\"] == 2:\n",
    "        example[\"source_0->subspaces\"] = [[0]]\n",
    "        example[\"source_1->subspaces\"] = [[1]] \n",
    "    return example\n",
    "\n",
    "for example in dataset:\n",
    "    add_locations(example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_collator(inputs):\n",
    "    for k, v in inputs.items():\n",
    "        if \"subspace\" in k:\n",
    "            inputs[k] = [v]\n",
    "        elif v is not None and isinstance(v, torch.Tensor):\n",
    "            inputs[k] = v.to(\"cuda\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignable.find_alignment(\n",
    "    train_dataloader=DataLoader(dataset, batch_size),\n",
    "    compute_loss=alignable.model.loss,\n",
    "    compute_metrics=classification_report,\n",
    "    inputs_collator=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate this model, we create a fresh IIT equality dataset consisting of 100 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "\n",
    "data = test_equality_model.generate_counterfactual_dataset(10000,\n",
    "                                                           intervention_id,\n",
    "                                                           64,\n",
    "                                                           equality_model.sample_input_tree_balanced)\n",
    "X_base_test, y_base_test, X_sources_test, y_II_test, interventions_test = data\n",
    "\n",
    "print(X_base_test.shape)\n",
    "print(y_base_test.shape)\n",
    "print(X_sources_test.shape)\n",
    "print(y_II_test.shape)\n",
    "print(interventions_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preds_test = LIM_trainer.predict(X_base_test.cpu(),device=\"cpu\")\n",
    "\n",
    "II_preds_test = LIM_trainer.iit_predict(X_base_test.cpu(),\n",
    "                                    X_sources_test.cpu(),\n",
    "                                    interventions_test.cpu(),\n",
    "                                    id_to_coords,\n",
    "                                    device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IIT-trained model does well in terms of a standard behavioral tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_base_test, base_preds_test.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, it _also_ performs perfectly on counterfactual examples â€“ certainly a marked improvement over the model we studied above that did no IIT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_II_test, II_preds_test.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "933b0a94e0d88ac80a17cb26ca3d8d36930c12815b02a2885c1925c2b1ae3c33"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
