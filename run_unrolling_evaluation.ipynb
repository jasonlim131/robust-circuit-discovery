{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f701b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_utils import *\n",
    "from logic_data.utils import *\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152e2630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using in a notebook env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: The testing components of [-h] [--gpu GPU]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--eval_batch_size EVAL_BATCH_SIZE] [--lr LR]\n",
      "                                 --data_path DATA_PATH --train_data_path\n",
      "                                 TRAIN_DATA_PATH --test_data_path\n",
      "                                 TEST_DATA_PATH\n",
      "                                 [--encoder_config_path ENCODER_CONFIG_PATH]\n",
      "                                 [--decoder_config_path DECODER_CONFIG_PATH]\n",
      "                                 [--max_seq_len MAX_SEQ_LEN] [--seed SEED]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 --output_dir OUTPUT_DIR\n",
      "                                 [--local_rank LOCAL_RANK] [--epochs EPOCHS]\n",
      "                                 [--model_path MODEL_PATH] [--warm_up WARM_UP]\n",
      "                                 [--is_wandb] [--log_step LOG_STEP]\n",
      "                                 [--valid_steps VALID_STEPS]\n",
      "                                 [--early_stopping EARLY_STOPPING]\n",
      "                                 [--device DEVICE] [--do_prealign_eval]\n",
      "                                 [--do_align] [--do_eval] [--do_test]\n",
      "                                 [--n_training_program N_TRAINING_PROGRAM]\n",
      "                                 [--n_fewshot N_FEWSHOT]\n",
      "                                 [--aligning_layer_n ALIGNING_LAYER_N]\n",
      "The testing components of: error: the following arguments are required: --data_path, --train_data_path, --test_data_path, --output_dir\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    is_notebook = False\n",
    "    try:\n",
    "        cmd = argparse.ArgumentParser('The testing components of')\n",
    "        cmd.add_argument('--gpu', default=-1, type=int, help='use id of gpu, -1 if cpu.')\n",
    "        cmd.add_argument('--train_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--eval_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "        cmd.add_argument('--data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument('--train_data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument('--test_data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument(\n",
    "            '--encoder_config_path', \n",
    "            type=str, help='path to the encoder config'\n",
    "        )\n",
    "        cmd.add_argument(\n",
    "            '--decoder_config_path', \n",
    "            type=str, help='path to the decoder config'\n",
    "        )\n",
    "        cmd.add_argument('--max_seq_len', default=512, type=int)\n",
    "        cmd.add_argument('--seed', default=42, type=int)\n",
    "        cmd.add_argument('--gradient_accumulation_steps', default=1, type=int)\n",
    "        cmd.add_argument('--output_dir', required=True, type=str, help='save dir')\n",
    "        cmd.add_argument('--local_rank', default=-1, type=int, help='multi gpu training')\n",
    "        cmd.add_argument('--epochs', default=10, type=int, help='training epochs')\n",
    "        cmd.add_argument('--model_path', type=str, required=False, default=None)\n",
    "        cmd.add_argument('--warm_up', type=float, default=0.1)\n",
    "        cmd.add_argument('--is_wandb', default=False, action='store_true')\n",
    "        cmd.add_argument('--log_step', default=10, type=int)\n",
    "        cmd.add_argument('--valid_steps', default=500, type=int)\n",
    "        cmd.add_argument('--early_stopping', default=5, type=int)\n",
    "        cmd.add_argument('--device', default=\"cuda\", type=str, help='')\n",
    "        cmd.add_argument('--do_prealign_eval', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_align', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_eval', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_test', default=False, action='store_true')\n",
    "        \n",
    "        cmd.add_argument('--n_training_program', default=5, type=int)\n",
    "        cmd.add_argument('--n_fewshot', default=6, type=int)\n",
    "        cmd.add_argument('--aligning_layer_n', default=0, type=int)\n",
    "        \n",
    "        args = cmd.parse_args(sys.argv[1:])\n",
    "    except:\n",
    "        is_notebook = True\n",
    "        parser = argparse.ArgumentParser()\n",
    "        args = parser.parse_args([])\n",
    "        args.gpu = 1\n",
    "        args.eval_batch_size = 64\n",
    "        args.gradient_accumulation_steps = 2\n",
    "        args.data_path = \"./logic_data\"\n",
    "        args.encoder_config_path = None\n",
    "        args.decoder_config_path = None\n",
    "        args.max_seq_len = 512\n",
    "        args.output_dir = \"./results_notebook/\"\n",
    "        args.epochs = 10\n",
    "        args.warm_up = 0.1\n",
    "        args.is_wandb = False\n",
    "        args.log_step = 10\n",
    "        args.valid_steps = 100 # -1 not do training eval!\n",
    "        args.early_stopping = 999 # large == never early stop!\n",
    "        args.device = \"cuda:0\"\n",
    "        args.do_prealign_eval = True # do it once at least!\n",
    "        args.do_align = True\n",
    "        args.do_eval = True\n",
    "        args.do_test = True\n",
    "        # args.model_path = None\n",
    "        \n",
    "        # alignment search setting\n",
    "        args.aligning_layer_n = 0\n",
    "        args.aligning_basis_n = 600\n",
    "        args.aligning_var_n = 1\n",
    "        \n",
    "        print(\"Using in a notebook env.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63352cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6ce5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6427.02it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.55it/s, acc=0.77]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.33it/s, acc=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13565.94it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.05it/s, acc=0.78]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.56it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10451.01it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.03it/s, acc=0.82]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.14it/s, acc=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8394.97it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.53it/s, acc=0.84]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.42it/s, acc=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7229.84it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.31it/s, acc=0.91]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.90it/s, acc=0.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6237.53it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.40it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.24it/s, acc=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5512.60it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.31it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.65it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4929.68it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.67it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.05it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4452.83it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.76it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.03it/s, acc=0.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4112.92it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.36it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.90it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20539.77it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.89it/s, acc=0.57]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.62it/s, acc=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13869.09it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.36it/s, acc=0.74]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.97it/s, acc=0.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10844.92it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.83it/s, acc=0.82]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.00it/s, acc=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8708.65it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.93it/s, acc=0.88]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.33it/s, acc=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7346.47it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.16it/s, acc=0.93]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.40it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6413.75it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.78it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.80it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5586.39it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.21it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.07it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4973.60it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.60it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.49it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4475.49it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.96it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.83it/s, acc=0.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4085.10it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.57it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.34it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20732.37it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.18it/s, acc=0.77]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.79it/s, acc=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13487.07it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.95it/s, acc=0.72]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.91it/s, acc=0.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10819.99it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.05it/s, acc=0.8]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.47it/s, acc=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8750.07it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.99it/s, acc=0.83]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.20it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7447.97it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.42it/s, acc=0.87]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.47it/s, acc=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6391.86it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.87it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.81it/s, acc=0.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5576.85it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.25it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.13it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4964.70it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.64it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.45it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4504.67it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.20it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.97it/s, acc=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4107.58it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.60it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.41it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20005.17it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.76it/s, acc=0.55]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.88it/s, acc=0.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13931.65it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.59it/s, acc=0.72]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.10it/s, acc=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10798.29it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.83it/s, acc=0.82]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.11it/s, acc=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8765.45it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.10it/s, acc=0.89]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.68it/s, acc=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7322.32it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.08it/s, acc=0.93]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.33it/s, acc=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6260.63it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.83it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.82it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5591.88it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.04it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.99it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4924.26it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.67it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.49it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4455.80it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.08it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.93it/s, acc=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( b == c )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4116.03it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(b==c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.61it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.39it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20649.80it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.91it/s, acc=0.73]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.88it/s, acc=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14121.33it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.84it/s, acc=0.78]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.64it/s, acc=0.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10441.33it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.77it/s, acc=0.81]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.10it/s, acc=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8590.61it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.03it/s, acc=0.88]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.24it/s, acc=0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7387.23it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.22it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.96it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6446.02it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.89it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.81it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5582.05it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.95it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.02it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4975.90it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.39it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.37it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4465.62it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.22it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.98it/s, acc=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4102.22it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.32it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.34it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20725.82it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.81it/s, acc=0.68]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.89it/s, acc=0.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14150.78it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.03it/s, acc=0.73]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.86it/s, acc=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10659.24it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.82it/s, acc=0.8]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.16it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8928.76it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.21it/s, acc=0.82]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.31it/s, acc=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7477.08it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.70it/s, acc=0.88]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.57it/s, acc=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6525.42it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.54it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.19it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3405.18it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.93it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.62it/s, acc=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4975.02it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.30it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.39it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4545.33it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.10it/s, acc=0.93]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.97it/s, acc=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( b != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4164.49it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(b!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.30it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.44it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20634.66it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.61it/s, acc=0.69]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.88it/s, acc=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14298.49it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.12it/s, acc=0.72]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.01it/s, acc=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10757.47it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.87it/s, acc=0.8]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.11it/s, acc=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8896.43it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.05it/s, acc=0.84]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.25it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7417.04it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.42it/s, acc=0.91]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.50it/s, acc=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6527.76it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.83it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.82it/s, acc=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5582.17it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.20it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.08it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5040.32it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.09it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.49it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4526.51it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.99it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.90it/s, acc=0.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) or ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4098.00it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)or(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.44it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.34it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20104.32it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.54it/s, acc=0.55]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.72it/s, acc=0.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14026.74it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.04it/s, acc=0.71]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.73it/s, acc=0.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10451.66it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.58it/s, acc=0.83]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.92it/s, acc=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8690.03it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.71it/s, acc=0.88]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.06it/s, acc=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7305.05it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.15it/s, acc=0.93]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.46it/s, acc=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6354.99it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.80it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.78it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5558.19it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.49it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.53it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4924.39it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.07it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.31it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4413.83it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.91it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.57it/s, acc=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4082.06it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.44it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.34it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 21085.38it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.79it/s, acc=0.72]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 18.76it/s, acc=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14360.02it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.45it/s, acc=0.76]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.97it/s, acc=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10991.10it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.78it/s, acc=0.81]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.09it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8873.40it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.12it/s, acc=0.83]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.23it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7436.93it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.60it/s, acc=0.89]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.50it/s, acc=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6493.74it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.90it/s, acc=0.93]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.85it/s, acc=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5588.96it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.36it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.20it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5035.28it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.43it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.85it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4416.08it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.26it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.47it/s, acc=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( b != c )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4064.06it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(b!=c).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.57it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.51it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20483.30it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 25.01it/s, acc=0.64]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.03it/s, acc=0.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13903.85it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.10it/s, acc=0.76]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.98it/s, acc=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10866.10it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.99it/s, acc=0.84]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.22it/s, acc=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8715.07it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.13it/s, acc=0.88]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.24it/s, acc=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7355.78it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.44it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.51it/s, acc=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6444.55it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.84it/s, acc=0.96]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.77it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5461.85it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.25it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.15it/s, acc=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4978.66it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.66it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.48it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4454.89it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.05it/s, acc=0.93]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.90it/s, acc=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c == a ) or ( a == b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4095.94it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c==a)or(a==b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.56it/s, acc=0.99]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.45it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 20740.37it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [8, 12]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.91it/s, acc=0.67]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.51it/s, acc=0.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 13820.33it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [15, 19]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 24.00it/s, acc=0.74]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.84it/s, acc=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10823.81it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [22, 26]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.83it/s, acc=0.82]\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.11it/s, acc=0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8787.38it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [29, 33]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 23.11it/s, acc=0.86]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.23it/s, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 7560.25it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [36, 40]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.10it/s, acc=0.92]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 15.47it/s, acc=0.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 6401.09it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [43, 47]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.92it/s, acc=0.95]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.83it/s, acc=0.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5620.24it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [50, 54]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21.25it/s, acc=0.97]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.14it/s, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5035.77it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [57, 61]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.32it/s, acc=0.98]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.37it/s, acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4525.28it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [64, 68]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.82it/s, acc=0.94]\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.87it/s, acc=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrolling for clauses:  ( c != a ) and ( a != b )\n",
      "seed:  42\n",
      "current n_shot:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4153.63it/s]\n",
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [71, 75]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.11.n_shot.10.seed.42.clauses.(c!=a)and(a!=b).align.left_aligment.seed.42/model-last model params: 0\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 19.22it/s, acc=0.99]\n",
      "Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.28it/s, acc=1]\n"
     ]
    }
   ],
   "source": [
    "training_clauses = [\n",
    "    '( c == a ) or ( a != b )',\n",
    "    '( c != a ) and ( a == b )',\n",
    "    '( c == a ) or ( b != c )',\n",
    "    '( c == a ) or ( b == c )',\n",
    "    '( c != a ) or ( a == b )',\n",
    "    '( b != a ) and ( b != c )',\n",
    "    '( c != a ) or ( a != b )',\n",
    "    '( c == a ) and ( b != c )',\n",
    "    '( c != a ) and ( b != c )',\n",
    "    '( c == a ) or ( a == b )',\n",
    "    '( c != a ) and ( a != b )'\n",
    "]\n",
    "align_type = \"left_aligment\"\n",
    "level = \"l2\"\n",
    "shared_train = True if level == \"l1\" else False\n",
    "n_fewshot = 10\n",
    "n_examples = n_fewshot + 1\n",
    "n_testing_examples = 1000\n",
    "saving_models = True\n",
    "\n",
    "for seed in [42,]: # [42, 66, 77, 88, 99]\n",
    "    for clauses in training_clauses:\n",
    "        for n_shot in range(1, n_fewshot+1):\n",
    "            args.seed = seed\n",
    "            set_seed(args.seed)\n",
    "            clauses_no_space = clauses.replace(\" \", \"\")\n",
    "            print(\"unrolling for clauses: \", clauses)\n",
    "            print(\"seed: \", seed)\n",
    "            print(\"current n_shot: \", n_shot)\n",
    "            # finding model files, it needs to exist on the disk.\n",
    "            model_name = f\"logic_pipeline.model.gpt2.n_rule.11.n_shot.{n_fewshot}.seed.{seed}.clauses.{clauses_no_space}.align.{align_type}.seed.{seed}/model-last\"\n",
    "            args.model_path = os.path.join(args.output_dir, model_name)\n",
    "            logger = logging.getLogger()\n",
    "            n_examples = n_shot+1\n",
    "            aligment_sampled_data = left_aligment_sampler(\n",
    "                clauses, n_testing_examples, n_examples = n_examples, shared_train=shared_train\n",
    "            )\n",
    "            test_data = {\n",
    "                \"base_input_ids\" : aligment_sampled_data[0],\n",
    "                \"base_output_ids\" : aligment_sampled_data[1],\n",
    "                \"source_input_ids\" : aligment_sampled_data[3],\n",
    "                \"source_output_ids\" : aligment_sampled_data[4],\n",
    "                \"counterfacut_output_ids\": aligment_sampled_data[6],\n",
    "                \"clauses\" : aligment_sampled_data[2],\n",
    "                \"intervention_ids\": [0 for i in range(len(aligment_sampled_data[0]))]\n",
    "            }\n",
    "            test_dataset = Dataset.from_dict(\n",
    "                {\n",
    "                    \"input_ids\": test_data[\"base_input_ids\"], \n",
    "                    \"labels\": test_data[\"base_output_ids\"],\n",
    "                    \"source_input_ids\": test_data[\"source_input_ids\"], \n",
    "                    \"counterfactual_labels\": test_data[\"counterfacut_output_ids\"],\n",
    "                    \"intervention_ids\": test_data[\"intervention_ids\"],\n",
    "                }\n",
    "            ).with_format(\"torch\")\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=args.eval_batch_size)\n",
    "            \n",
    "            # Model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            configuration = GPT2Config.from_pretrained(os.path.join(args.data_path, \"decoder_config.json\"))\n",
    "\n",
    "            if \"logic\" in model_name:\n",
    "                arity = 3\n",
    "            start_idx = 1 + (arity + 4) * int(n_shot)\n",
    "            end_idx = start_idx + (arity+1)\n",
    "            alignment_config = {\n",
    "                \"layer\" : args.aligning_layer_n,\n",
    "                \"token_range\" : [start_idx, end_idx] # this is kind of fixed?\n",
    "            }\n",
    "            if args.aligning_var_n == 1:\n",
    "                intervention_config = {\n",
    "                    0: [[0, args.aligning_basis_n]]\n",
    "                }\n",
    "            elif args.aligning_var_n == 2:\n",
    "                pass\n",
    "            logging.info(f\"intervention_config = {intervention_config}\")\n",
    "            logging.info(f\"alignment_config = {alignment_config}\")\n",
    "\n",
    "            model = AlignableGPT2LMHeadModel(configuration, alignment_config=alignment_config)\n",
    "            if args.model_path is not None:\n",
    "                logging.info(\"Loading pretrained model.\")\n",
    "                raw_weights = torch.load(os.path.join(args.model_path, 'pytorch_model.bin'))\n",
    "                model.load_state_dict(raw_weights, strict=False)\n",
    "\n",
    "            # we need to set off gradients!\n",
    "            for name, param in model.named_parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            device = torch.device(args.device)\n",
    "            if \"cuda:\" not in args.device:\n",
    "                n_gpu = torch.cuda.device_count()\n",
    "                logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "            else:\n",
    "                n_gpu = 1\n",
    "                logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "\n",
    "            if n_gpu > 1:\n",
    "                model = torch.nn.DataParallel(model)\n",
    "            _ = model.to(device)\n",
    "\n",
    "            aligner = LogicSolverAligner(\n",
    "                model, device=device, \n",
    "                logger=logger,\n",
    "                is_master=True, \n",
    "                n_gpu=n_gpu,\n",
    "                is_wandb=args.is_wandb, \n",
    "                model_name=model_name,\n",
    "                intervention_config=intervention_config\n",
    "            )\n",
    "            num_params = count_parameters(model)\n",
    "            logging.info(f'Number of {model_name} model params: {num_params}')\n",
    "        \n",
    "            # task performance with unrolling.\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            _ = model.eval()\n",
    "            epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                input_ids = inputs['input_ids'].to(device)\n",
    "                labels = inputs['labels'].to(device)\n",
    "                outputs = model(input_ids=input_ids)\n",
    "                actual_test_labels = labels[:, -3]\n",
    "                pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "                correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                total_count += len(correct_labels)\n",
    "                correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "                current_acc = round(correct_count/total_count, 2)\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "            task_acc = round(correct_count/total_count, 2)\n",
    "\n",
    "            # iia with unrolling.\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            aligner.model.eval()\n",
    "            epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                for k, v in inputs.items():\n",
    "                    if v is not None and isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(device)\n",
    "                if aligner.preload_intervention_corr is not None:\n",
    "                    intervention_corr = aligner.preload_intervention_corr.expand(\n",
    "                        inputs['input_ids'].shape[0],-1\n",
    "                    ).to(device)\n",
    "                else:\n",
    "                    assert False # not implemented\n",
    "\n",
    "                # aligning forward!\n",
    "                source_hidden_states = aligner.model(\n",
    "                   input_ids=inputs['source_input_ids']\n",
    "                ).rotated_hidden_states\n",
    "                outputs = aligner.model(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    source_hidden_states=source_hidden_states,\n",
    "                    intervention_corr=intervention_corr,\n",
    "                    labels=inputs['counterfactual_labels']\n",
    "                )\n",
    "\n",
    "                actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "                pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "                correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                total_count += len(correct_labels)\n",
    "                correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "                current_acc = round(correct_count/total_count, 2)\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "            iia_acc = round(correct_count/total_count, 2)\n",
    "\n",
    "            results += [[clauses, n_shot, seed, task_acc, iia_acc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f36553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results, columns = [\n",
    "    'clauses', 'n_shot', 'seed', 'task_acc', 'iit_acc'\n",
    "])\n",
    "result_df = result_df.groupby(\n",
    "    ['n_shot'], as_index=False\n",
    ").mean()[\n",
    "    ['n_shot', 'task_acc', 'iit_acc']\n",
    "]\n",
    "plot_df = result_df[['n_shot', 'task_acc', 'iit_acc']].melt('n_shot', var_name='cols',  value_name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca82fe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 410.25x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.catplot(\n",
    "    x=\"n_shot\", y=\"acc\", hue='cols', \n",
    "    data=plot_df, kind='point', height=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa2cdf",
   "metadata": {},
   "source": [
    "### Zero-shot representation transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.test_data_path = \\\n",
    "    \"./logic_data/left_aligment_test_data.l1.clauses.(c!=b)and(c!=a).pkl\"\n",
    "test_data = pickle.load(open(args.test_data_path, 'rb'))\n",
    "\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": test_data[\"base_input_ids\"], \n",
    "        \"labels\": test_data[\"base_output_ids\"],\n",
    "        \"source_input_ids\": test_data[\"source_input_ids\"], \n",
    "        \"counterfactual_labels\": test_data[\"counterfacut_output_ids\"],\n",
    "        \"intervention_ids\": test_data[\"intervention_ids\"],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.eval_batch_size)\n",
    "\n",
    "# Model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "total_count = 0\n",
    "correct_count = 0\n",
    "if args.do_test:\n",
    "    aligner.model.eval()\n",
    "    epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(device)\n",
    "        if aligner.preload_intervention_corr is not None:\n",
    "            intervention_corr = aligner.preload_intervention_corr.expand(\n",
    "                inputs['input_ids'].shape[0],-1\n",
    "            ).to(device)\n",
    "        else:\n",
    "            assert False # not implemented\n",
    "\n",
    "        # aligning forward!\n",
    "        source_hidden_states = aligner.model(\n",
    "           input_ids=inputs['source_input_ids']\n",
    "        ).rotated_hidden_states\n",
    "        outputs = aligner.model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            source_hidden_states=source_hidden_states,\n",
    "            intervention_corr=intervention_corr,\n",
    "            labels=inputs['counterfactual_labels']\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "        current_acc = round(correct_count/total_count, 2)\n",
    "        epoch_iterator.set_postfix({'acc': current_acc})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
