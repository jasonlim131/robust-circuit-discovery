{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaf9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, argparse, sys, pickle, time\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from models.modelings_alignable_gpt2 import *\n",
    "from logic_data.constants import *\n",
    "from datasets import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28ef4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicSolverAligner(object):\n",
    "    def __init__(\n",
    "        self, model,\n",
    "        is_master,\n",
    "        device,\n",
    "        logger,\n",
    "        lr=5e-5,\n",
    "        apex_enable=False,\n",
    "        n_gpu=1,\n",
    "        early_stopping=5,\n",
    "        do_statistic=False,\n",
    "        is_wandb=False,\n",
    "        model_name=\"\",\n",
    "        intervention_config=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.is_master = is_master\n",
    "        self.logger = logger\n",
    "        self.is_wandb = is_wandb\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.n_gpu = n_gpu\n",
    "    \n",
    "        self.early_stopping = early_stopping\n",
    "    \n",
    "        self.intervention_config = intervention_config\n",
    "        self.preload_intervention_corr = None\n",
    "        # this is to make things a little faster.\n",
    "        if len(list(self.intervention_config.keys())) == 1:\n",
    "            self.preload_intervention_corr = self.intervention_config[\n",
    "                list(self.intervention_config.keys())[0]\n",
    "            ]\n",
    "            self.preload_intervention_corr = torch.tensor(self.preload_intervention_corr).long()\n",
    "    \n",
    "    def train(\n",
    "        self, train_dataloader, dev_dataloader,\n",
    "        optimizer, scheduler, output_dir,\n",
    "        log_step, valid_steps, epochs, \n",
    "        gradient_accumulation_steps,\n",
    "    ):\n",
    "        # okay, have to honest, not sure whether we do train mode align or eval align;\n",
    "        # i guess it is good to try both, but ... only trying train here and move on.\n",
    "        self.model.train()\n",
    "        train_iterator = trange(\n",
    "            0, int(epochs), desc=\"Epoch\"\n",
    "        )\n",
    "        total_step = 0\n",
    "        total_log_step = 0\n",
    "        best_eval_acc = -1\n",
    "        for epoch in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True)\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                for k, v in inputs.items():\n",
    "                    if v is not None and isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(self.device)\n",
    "                        \n",
    "                if self.preload_intervention_corr is not None:\n",
    "                    intervention_corr = self.preload_intervention_corr.expand(\n",
    "                        inputs['input_ids'].shape[0],-1\n",
    "                    ).to(self.device)\n",
    "                else:\n",
    "                    assert False # not implemented\n",
    "                \n",
    "                # aligning forward!\n",
    "                source_hidden_states = self.model(\n",
    "                   input_ids=inputs['source_input_ids']\n",
    "                ).rotated_hidden_states\n",
    "                outputs = self.model(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    source_hidden_states=source_hidden_states,\n",
    "                    intervention_corr=intervention_corr,\n",
    "                    labels=inputs['counterfactual_labels']\n",
    "                )\n",
    "                loss = outputs.loss.mean() if self.n_gpu > 1 else outputs.loss\n",
    "                \n",
    "                actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "                pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "                correct_labels = (actual_test_labels==pred_test_labels)\n",
    "                \n",
    "                step_accuracy = correct_labels.sum() / correct_labels.shape[0]\n",
    "                step_accuracy = step_accuracy.tolist()\n",
    "\n",
    "                if total_step % log_step == 0 and self.is_wandb:\n",
    "                    wandb.log(\n",
    "                        {\n",
    "                            \"train/loss\": loss.item(),\n",
    "                            \"train/step_accuracy\": step_accuracy\n",
    "                        },\n",
    "                        step=total_log_step\n",
    "                    )\n",
    "                    \n",
    "                    if total_step % valid_steps == 0:\n",
    "                        total_count = 0\n",
    "                        correct_count = 0\n",
    "                        self.model.eval()\n",
    "                        for step, inputs in enumerate(dev_dataloader):\n",
    "                            for k, v in inputs.items():\n",
    "                                if v is not None and isinstance(v, torch.Tensor):\n",
    "                                    inputs[k] = v.to(self.device)\n",
    "                            if self.preload_intervention_corr is not None:\n",
    "                                intervention_corr = self.preload_intervention_corr.expand(\n",
    "                                    inputs['input_ids'].shape[0],-1\n",
    "                                ).to(self.device)\n",
    "                            else:\n",
    "                                assert False # not implemented\n",
    "\n",
    "                            # aligning forward!\n",
    "                            source_hidden_states = self.model(\n",
    "                               input_ids=inputs['source_input_ids']\n",
    "                            ).rotated_hidden_states\n",
    "                            outputs = self.model(\n",
    "                                input_ids=inputs['input_ids'],\n",
    "                                source_hidden_states=source_hidden_states,\n",
    "                                intervention_corr=intervention_corr,\n",
    "                                labels=inputs['counterfactual_labels']\n",
    "                            )\n",
    "\n",
    "                            actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "                            pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "                            correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                            total_count += len(correct_labels)\n",
    "                            correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "                        current_acc = round(correct_count/total_count, 2)\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"eval/accuracy\": current_acc\n",
    "                            },\n",
    "                            step=total_log_step\n",
    "                        )\n",
    "                        if current_acc > best_eval_acc:\n",
    "                            best_eval_acc = current_acc\n",
    "                            if self.is_master:\n",
    "                                if self.n_gpu > 1:\n",
    "                                    self.model.module.save_pretrained(os.path.join(output_dir, 'model-best'))\n",
    "                                else:\n",
    "                                    self.model.save_pretrained(os.path.join(output_dir, 'model-best'))\n",
    "                        self.model.train()\n",
    "                        \n",
    "                    \n",
    "                    total_log_step += 1\n",
    "                loss_str = round(loss.item(), 2)\n",
    "                epoch_iterator.set_postfix({'loss': loss_str})\n",
    "                \n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                if total_step % gradient_accumulation_steps == 0:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    self.model.zero_grad()\n",
    "                    \n",
    "                total_step += 1\n",
    "                \n",
    "        logging.info(\"Training is finished ...\") \n",
    "        if self.is_master:\n",
    "            if self.n_gpu > 1:\n",
    "                self.model.module.save_pretrained(os.path.join(output_dir, 'model-last'))\n",
    "            else:\n",
    "                self.model.save_pretrained(os.path.join(output_dir, 'model-last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2708fbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using in a notebook env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: The testing components of [-h] [--gpu GPU]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--eval_batch_size EVAL_BATCH_SIZE] [--lr LR]\n",
      "                                 --data_path DATA_PATH --train_data_path\n",
      "                                 TRAIN_DATA_PATH --test_data_path\n",
      "                                 TEST_DATA_PATH\n",
      "                                 [--encoder_config_path ENCODER_CONFIG_PATH]\n",
      "                                 [--decoder_config_path DECODER_CONFIG_PATH]\n",
      "                                 [--max_seq_len MAX_SEQ_LEN] [--seed SEED]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 --output_dir OUTPUT_DIR\n",
      "                                 [--local_rank LOCAL_RANK] [--epochs EPOCHS]\n",
      "                                 [--model_path MODEL_PATH] [--warm_up WARM_UP]\n",
      "                                 [--is_wandb] [--log_step LOG_STEP]\n",
      "                                 [--valid_steps VALID_STEPS]\n",
      "                                 [--early_stopping EARLY_STOPPING]\n",
      "                                 [--device DEVICE] [--do_prealign_eval]\n",
      "                                 [--do_align] [--do_eval] [--do_test]\n",
      "                                 [--n_training_program N_TRAINING_PROGRAM]\n",
      "                                 [--n_fewshot N_FEWSHOT]\n",
      "                                 [--aligning_layer_n ALIGNING_LAYER_N]\n",
      "The testing components of: error: the following arguments are required: --data_path, --train_data_path, --test_data_path, --output_dir\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    is_notebook = False\n",
    "    try:\n",
    "        cmd = argparse.ArgumentParser('The testing components of')\n",
    "        cmd.add_argument('--gpu', default=-1, type=int, help='use id of gpu, -1 if cpu.')\n",
    "        cmd.add_argument('--train_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--eval_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "        cmd.add_argument('--data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument('--train_data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument('--test_data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument(\n",
    "            '--encoder_config_path', \n",
    "            type=str, help='path to the encoder config'\n",
    "        )\n",
    "        cmd.add_argument(\n",
    "            '--decoder_config_path', \n",
    "            type=str, help='path to the decoder config'\n",
    "        )\n",
    "        cmd.add_argument('--max_seq_len', default=512, type=int)\n",
    "        cmd.add_argument('--seed', default=42, type=int)\n",
    "        cmd.add_argument('--gradient_accumulation_steps', default=1, type=int)\n",
    "        cmd.add_argument('--output_dir', required=True, type=str, help='save dir')\n",
    "        cmd.add_argument('--local_rank', default=-1, type=int, help='multi gpu training')\n",
    "        cmd.add_argument('--epochs', default=10, type=int, help='training epochs')\n",
    "        cmd.add_argument('--model_path', type=str, required=False, default=None)\n",
    "        cmd.add_argument('--warm_up', type=float, default=0.1)\n",
    "        cmd.add_argument('--is_wandb', default=False, action='store_true')\n",
    "        cmd.add_argument('--log_step', default=10, type=int)\n",
    "        cmd.add_argument('--valid_steps', default=500, type=int)\n",
    "        cmd.add_argument('--early_stopping', default=5, type=int)\n",
    "        cmd.add_argument('--device', default=\"cuda\", type=str, help='')\n",
    "        cmd.add_argument('--do_prealign_eval', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_align', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_eval', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_test', default=False, action='store_true')\n",
    "        \n",
    "        cmd.add_argument('--n_training_program', default=5, type=int)\n",
    "        cmd.add_argument('--n_fewshot', default=6, type=int)\n",
    "        cmd.add_argument('--aligning_layer_n', default=0, type=int)\n",
    "        \n",
    "        args = cmd.parse_args(sys.argv[1:])\n",
    "    except:\n",
    "        is_notebook = True\n",
    "        parser = argparse.ArgumentParser()\n",
    "        args = parser.parse_args([])\n",
    "        args.gpu = 1\n",
    "        args.train_batch_size = 64\n",
    "        args.eval_batch_size = 64\n",
    "        args.gradient_accumulation_steps = 2\n",
    "        args.lr = 1e-3\n",
    "        args.data_path = \"./logic_data\"\n",
    "        args.train_data_path = \\\n",
    "            \"\"\n",
    "        args.test_data_path = \\\n",
    "            \"\"\n",
    "        args.encoder_config_path = None\n",
    "        args.decoder_config_path = None\n",
    "        args.max_seq_len = 512\n",
    "        args.seed = 42\n",
    "        args.output_dir = \"./results_notebook/\"\n",
    "        args.epochs = 10\n",
    "        args.warm_up = 0.1\n",
    "        args.is_wandb = False\n",
    "        args.log_step = 10\n",
    "        args.valid_steps = 100 # -1 not do training eval!\n",
    "        args.early_stopping = 999 # large == never early stop!\n",
    "        args.device = \"cuda:0\"\n",
    "        args.do_prealign_eval = True # do it once at least!\n",
    "        args.do_align = True\n",
    "        args.do_eval = True\n",
    "        args.do_test = True\n",
    "        args.model_path = \"./results_notebook/logic_pipeline.model.gpt2.n_rule.7.n_shot.14.seed.42/model-last/\"\n",
    "        # args.model_path = None\n",
    "        \n",
    "        # alignment search setting\n",
    "        args.aligning_layer_n = 0\n",
    "        args.aligning_basis_n = 600\n",
    "        args.aligning_var_n = 1\n",
    "        \n",
    "        print(\"Using in a notebook env.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74a265ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:intervention_config = {0: [[0, 600]]}\n",
      "INFO:root:alignment_config = {'layer': 0, 'token_range': [1, 5]}\n",
      "INFO:root:Loading pretrained model.\n",
      "INFO:root:__Number CUDA Devices: 1\n",
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 27.29it/s, acc=0.79]\n"
     ]
    }
   ],
   "source": [
    "args.train_data_path = \\\n",
    "f\"./logic_data/left_aligment_test_data.l1.unrolling.{s}.clauses.(c==b)and(c!=a).pkl\"\n",
    "args.test_data_path = \\\n",
    "f\"./logic_data/left_aligment_test_data.l1.unrolling.{s}.clauses.(c==b)and(c!=a).pkl\"\n",
    "if args.model_path is None:\n",
    "    model_name = \"logic_pipeline.model.gpt2.n_rule.7.n_shot.14.seed.42\"\n",
    "else:\n",
    "    model_name = args.model_path.strip(\"/\").split(\"/\")[-2]\n",
    "align_dataname = args.train_data_path.split(\"/\")[-1].split(\".pkl\")[0]\n",
    "run_name = f\"{model_name}.data.{align_dataname}.seed.{args.seed}\"\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Dataloader\n",
    "train_data = pickle.load(open(args.train_data_path, 'rb'))\n",
    "test_data = pickle.load(open(args.test_data_path, 'rb'))\n",
    "\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": train_data[\"base_input_ids\"], \n",
    "        \"labels\": train_data[\"base_output_ids\"],\n",
    "        \"source_input_ids\": train_data[\"source_input_ids\"], \n",
    "        \"counterfactual_labels\": train_data[\"counterfacut_output_ids\"],\n",
    "        \"intervention_ids\": train_data[\"intervention_ids\"],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.train_batch_size)\n",
    "\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": test_data[\"base_input_ids\"], \n",
    "        \"labels\": test_data[\"base_output_ids\"],\n",
    "        \"source_input_ids\": test_data[\"source_input_ids\"], \n",
    "        \"counterfactual_labels\": test_data[\"counterfacut_output_ids\"],\n",
    "        \"intervention_ids\": test_data[\"intervention_ids\"],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.eval_batch_size)\n",
    "\n",
    "# Model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "configuration = GPT2Config.from_pretrained(os.path.join(args.data_path, \"decoder_config.json\"))\n",
    "\n",
    "if \"logic\" in model_name:\n",
    "    arity = 3\n",
    "idx = 0\n",
    "for token in model_name.split(\".\"):\n",
    "    if token == \"n_shot\":\n",
    "        break\n",
    "    idx += 1\n",
    "n_shot = model_name.split(\".\")[idx+1]\n",
    "\n",
    "if \"unrolling\" in args.train_data_path:\n",
    "    idx = 0\n",
    "    for token in args.train_data_path.split(\".\"):\n",
    "        if token == \"unrolling\":\n",
    "            break\n",
    "        idx += 1\n",
    "    n_shot = args.train_data_path.split(\".\")[idx+1]\n",
    "    # reset to unrolling position\n",
    "\n",
    "start_idx = 1 + (arity + 4) * int(n_shot)\n",
    "end_idx = start_idx + (arity+1)\n",
    "\n",
    "alignment_config = {\n",
    "    \"layer\" : args.aligning_layer_n,\n",
    "    \"token_range\" : [start_idx, end_idx] # this is kind of fixed?\n",
    "}\n",
    "if args.aligning_var_n == 1:\n",
    "    intervention_config = {\n",
    "        0: [[0, args.aligning_basis_n]]\n",
    "    }\n",
    "elif args.aligning_var_n == 2:\n",
    "    pass\n",
    "logging.info(f\"intervention_config = {intervention_config}\")\n",
    "logging.info(f\"alignment_config = {alignment_config}\")\n",
    "\n",
    "model = AlignableGPT2LMHeadModel(configuration, alignment_config=alignment_config)\n",
    "if args.model_path is not None:\n",
    "    logging.info(\"Loading pretrained model.\")\n",
    "    raw_weights = torch.load(os.path.join(args.model_path, 'pytorch_model.bin'))\n",
    "    model.load_state_dict(raw_weights, strict=False)\n",
    "\n",
    "# we need to set off gradients!\n",
    "for name, param in model.named_parameters():\n",
    "    if \"rotate_layer\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "set_seed(args.seed)\n",
    "device = torch.device(args.device)\n",
    "if \"cuda:\" not in args.device:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "else:\n",
    "    n_gpu = 1\n",
    "    logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "\n",
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "_ = model.to(device)\n",
    "\n",
    "t_total = int(len(train_dataloader) * args.epochs)\n",
    "\n",
    "warm_up_steps = args.warm_up * t_total\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=args.lr\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warm_up_steps,\n",
    "                                            num_training_steps=t_total)\n",
    "is_master = True                                    \n",
    "if not os.path.exists(args.output_dir) and is_master:\n",
    "    os.mkdir(args.output_dir)\n",
    "os.environ[\"WANDB_PROJECT\"] = f\"ToM-DAS\"\n",
    "\n",
    "output_dir = os.path.join(args.output_dir, run_name)\n",
    "if args.do_align and args.is_wandb:\n",
    "    import wandb\n",
    "    run = wandb.init(\n",
    "        project=\"ToM-DAS-GPT2\", \n",
    "        entity=\"wuzhengx\",\n",
    "        name=run_name,\n",
    "    )\n",
    "    wandb.config.update(args)\n",
    "if not os.path.exists(args.output_dir) and is_master:\n",
    "    os.mkdir(args.output_dir)\n",
    "\n",
    "if args.do_prealign_eval:\n",
    "    # before doing alignment, we need to check factual performance on the dataset.\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    if args.do_eval:\n",
    "        _ = model.eval()\n",
    "        epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "        for step, inputs in enumerate(epoch_iterator):\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            labels = inputs['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            actual_test_labels = labels[:, -3]\n",
    "            pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "            correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "            total_count += len(correct_labels)\n",
    "            correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            epoch_iterator.set_postfix({'acc': current_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8ae5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of logic_pipeline.model.gpt2.n_rule.7.n_shot.14.seed.42 model params: 1440000\n"
     ]
    }
   ],
   "source": [
    "aligner = LogicSolverAligner(\n",
    "    model, device=device, \n",
    "    logger=logger,\n",
    "    is_master=is_master, \n",
    "    n_gpu=n_gpu,\n",
    "    is_wandb=args.is_wandb, \n",
    "    model_name=model_name,\n",
    "    intervention_config=intervention_config\n",
    ")\n",
    "num_params = count_parameters(model)\n",
    "logging.info(f'Number of {model_name} model params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086ad56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:OUTPUT DIR: ./results_notebook/logic_pipeline.model.gpt2.n_rule.7.n_shot.14.seed.42.data.left_aligment_train_data.l1.clauses.(c==a)or(b!=a).seed.42\n",
      "Epoch: 0:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 262/313 [00:36<00:07,  7.25it/s, loss=0]\n",
      "Epoch:   0%|                                                                                                                                                                   | 0/10 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdo_align:\n\u001b[1;32m      3\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUTPUT DIR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m, in \u001b[0;36mLogicSolverAligner.train\u001b[0;34m(self, train_dataloader, dev_dataloader, optimizer, scheduler, output_dir, log_step, valid_steps, epochs, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m train_iterator:\n\u001b[1;32m     53\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/arrow_dataset.py:2601\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/arrow_dataset.py:2586\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2584\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2585\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2586\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:634\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    632\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:406\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py:81\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping:\n\u001b[0;32m---> 81\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(row)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:158\u001b[0m, in \u001b[0;36mNumpyArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:164\u001b[0m, in \u001b[0;36mNumpyArrowExtractor.extract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {col: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arrow_array_to_numpy(pa_table[col]) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names}\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:164\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {col: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arrow_array_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names}\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/datasets/formatting/formatting.py:168\u001b[0m, in \u001b[0;36mNumpyArrowExtractor._arrow_array_to_numpy\u001b[0;34m(self, pa_array)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arrow_array_to_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_array: pa\u001b[38;5;241m.\u001b[39mArray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pa_array, pa\u001b[38;5;241m.\u001b[39mChunkedArray):\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mpa_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m, _ArrayXDExtensionType):\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;66;03m# don't call to_pylist() to preserve dtype of the fixed-size array\u001b[39;00m\n\u001b[1;32m    170\u001b[0m             zero_copy_only \u001b[38;5;241m=\u001b[39m _is_zero_copy_only(pa_array\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mstorage_dtype, unnest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m pa_array\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "if args.do_align:\n",
    "    logging.info(f\"OUTPUT DIR: {output_dir}\")\n",
    "    aligner.train(\n",
    "        train_dataloader, test_dataloader,\n",
    "        optimizer, scheduler, \n",
    "        log_step=args.log_step, valid_steps=args.valid_steps,\n",
    "        output_dir=output_dir, epochs=args.epochs, \n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef069adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.is_wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133fc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 10.23it/s, acc=0.68]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "if args.do_test: \n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    if args.do_test:\n",
    "        aligner.model.eval()\n",
    "        epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "        for step, inputs in enumerate(epoch_iterator):\n",
    "            for k, v in inputs.items():\n",
    "                if v is not None and isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(device)\n",
    "            if aligner.preload_intervention_corr is not None:\n",
    "                intervention_corr = aligner.preload_intervention_corr.expand(\n",
    "                    inputs['input_ids'].shape[0],-1\n",
    "                ).to(device)\n",
    "            else:\n",
    "                assert False # not implemented\n",
    "\n",
    "            # aligning forward!\n",
    "            source_hidden_states = aligner.model(\n",
    "               input_ids=inputs['source_input_ids']\n",
    "            ).rotated_hidden_states\n",
    "            outputs = aligner.model(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                source_hidden_states=source_hidden_states,\n",
    "                intervention_corr=intervention_corr,\n",
    "                labels=inputs['counterfactual_labels']\n",
    "            )\n",
    "\n",
    "            actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "            pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "            correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "            total_count += len(correct_labels)\n",
    "            correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            epoch_iterator.set_postfix({'acc': current_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25a1cc",
   "metadata": {},
   "source": [
    "### Zero-shot representation transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33002fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:28<00:00, 11.13it/s, acc=0.71]\n"
     ]
    }
   ],
   "source": [
    "args.test_data_path = \"./logic_data/left_aligment_train_data.l3.clauses.(c==a)or(b!=a)+(c==a)and(a==b).pkl\"\n",
    "test_data = pickle.load(open(args.test_data_path, 'rb'))\n",
    "\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": test_data[\"base_input_ids\"], \n",
    "        \"labels\": test_data[\"base_output_ids\"],\n",
    "        \"source_input_ids\": test_data[\"source_input_ids\"], \n",
    "        \"counterfactual_labels\": test_data[\"counterfacut_output_ids\"],\n",
    "        \"intervention_ids\": test_data[\"intervention_ids\"],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.eval_batch_size)\n",
    "\n",
    "# Model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "total_count = 0\n",
    "correct_count = 0\n",
    "if args.do_test:\n",
    "    aligner.model.eval()\n",
    "    epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(device)\n",
    "        if aligner.preload_intervention_corr is not None:\n",
    "            intervention_corr = aligner.preload_intervention_corr.expand(\n",
    "                inputs['input_ids'].shape[0],-1\n",
    "            ).to(device)\n",
    "        else:\n",
    "            assert False # not implemented\n",
    "\n",
    "        # aligning forward!\n",
    "        source_hidden_states = aligner.model(\n",
    "           input_ids=inputs['source_input_ids']\n",
    "        ).rotated_hidden_states\n",
    "        outputs = aligner.model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            source_hidden_states=source_hidden_states,\n",
    "            intervention_corr=intervention_corr,\n",
    "            labels=inputs['counterfactual_labels']\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['counterfactual_labels'][:, -3]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -4], dim=-1)\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "        current_acc = round(correct_count/total_count, 2)\n",
    "        epoch_iterator.set_postfix({'acc': current_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9794599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
