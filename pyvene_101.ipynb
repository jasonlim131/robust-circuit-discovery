{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6c7e19",
   "metadata": {},
   "source": [
    "# Introduction to pyvene\n",
    "This tutorial shows simple runnable code snippets of how to do different kinds of interventions on neural networks with pyvene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6994fa",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stanfordnlp/pyvene/blob/main/pyvene/pyvene_101.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d123a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Zhengxuan Wu\"\n",
    "__version__ = \"01/19/2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706e21b",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import pyvene\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    !pip install git+https://github.com/frankaging/pyvene.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede4f94",
   "metadata": {},
   "source": [
    "## pyvene 101\n",
    "\n",
    "### simplest, auto-cast everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82664f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"source_representation\": torch.zeros(\n",
    "        gpt2.config.n_embd)\n",
    "}, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890fda4",
   "metadata": {},
   "source": [
    "### standalone config allows more options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4faa3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "IntervenableConfig\n",
      "{\n",
      "    \"model_type\": \"None\",\n",
      "    \"representations\": [\n",
      "        {\n",
      "            \"layer\": 0,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 1,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 2,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 3,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        }\n",
      "    ],\n",
      "    \"intervention_types\": \"<class 'pyvene.models.interventions.VanillaIntervention'>\",\n",
      "    \"mode\": \"parallel\",\n",
      "    \"interventions\": [\n",
      "        \"None\"\n",
      "    ],\n",
      "    \"sorted_keys\": \"None\",\n",
      "    \"intervention_dimensions\": \"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    {\n",
    "        \"layer\": _,\n",
    "        \"component\": \"mlp_output\",\n",
    "        \"source_representation\": torch.zeros(\n",
    "            gpt2.config.n_embd)\n",
    "    } for _ in range(4)],\n",
    "    mode=\"parallel\"\n",
    ")\n",
    "print(config)\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfb510",
   "metadata": {},
   "source": [
    "### passing activations at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a44144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_output\",\n",
    "}, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    source_representations = torch.zeros(gpt2.config.n_embd),\n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2270",
   "metadata": {},
   "source": [
    "### simple addition intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40f5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_input\"},\n",
    "    pv.AdditionIntervention\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The Space Needle is in downtown\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"base\": [[[0, 1, 2, 3]]]},\n",
    "    source_representations = torch.rand(gpt2.config.n_embd)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ddf77",
   "metadata": {},
   "source": [
    "### trainable interventions accept additional arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f058ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"block_output\",\n",
    "    \"low_rank_dimension\": 1},\n",
    "    pv.LowRankRotatedSpaceIntervention\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "last_hidden_state = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    sources = tokenizer(\n",
    "        \"The capital of Italy is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"sources->base\": 3}\n",
    ")[-1].last_hidden_state\n",
    "\n",
    "loss = last_hidden_state.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd2b8e",
   "metadata": {},
   "source": [
    "### collect activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6bd585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 10,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.CollectIntervention}\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"sources->base\": 3}\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0d0c6",
   "metadata": {},
   "source": [
    "### collect activations work organically with interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adcfcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.VanillaIntervention}\n",
    ")\n",
    "\n",
    "config.add_intervention({\n",
    "    \"layer\": 10,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.CollectIntervention})\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    sources = [tokenizer(\n",
    "        \"The capital of Italy is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), None], \n",
    "    unit_locations={\"sources->base\": 3}\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6e4d9",
   "metadata": {},
   "source": [
    "### Fine-grained intervention on a specific neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25b6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"head_attention_value_output\",\n",
    "    \"unit\": \"h.pos\",\n",
    "    \"intervention_type\": pv.CollectIntervention}\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\n",
    "        \"base\": pv.GET_LOC((3,3))\n",
    "    },\n",
    "    subspaces=[0]\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692bc15",
   "metadata": {},
   "source": [
    "### New intervention type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1597221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "class MultiplierIntervention(\n",
    "  pv.ConstantSourceIntervention):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(\n",
    "    self, base, source=None, subspaces=None):\n",
    "        return base * 99.0\n",
    "# run with new intervention type\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "  \"intervention_type\": MultiplierIntervention}, \n",
    "  model=gpt2)\n",
    "intervened_outputs = pv_gpt2(\n",
    "  base = tokenizer(\"The capital of Spain is\", \n",
    "    return_tensors=\"pt\"), \n",
    "  unit_locations={\"base\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079050f6",
   "metadata": {},
   "source": [
    "### Recurrent NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a53347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, _, gru = pv.create_gru_classifier(\n",
    "    pv.GRUConfig(h_dim=32))\n",
    "\n",
    "pv_gru = pv.IntervenableModel({\n",
    "    \"component\": \"cell_output\",\n",
    "    \"unit\": \"t\", \n",
    "    \"intervention_type\": pv.ZeroIntervention},\n",
    "    model=gru)\n",
    "\n",
    "rand_t = torch.rand(1,10, gru.config.h_dim)\n",
    "\n",
    "intervened_outputs = pv_gru(\n",
    "  base = {\"inputs_embeds\": rand_t}, \n",
    "  unit_locations={\"base\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121366c1",
   "metadata": {},
   "source": [
    "### LMs Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f718e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy was walking in the park when she saw a big, red balloon. She was so excited and wanted to play with it.\n",
      "\n",
      "But then, a big, mean man came and said, \"That balloon is mine! You can't have it!\" Lucy was very sad and started to cry.\n",
      "\n",
      "The man said, \"I'm sorry, but I need the balloon for my work. You can have it if you want.\"\n",
      "\n",
      "Lucy was so happy and said, \"Yes please!\" She took the balloon and ran away.\n",
      "\n",
      "But then, the man said, \"Wait! I have an idea. Let's make a deal. If you can guess what I'm going to give you, then you can have the balloon.\"\n",
      "\n",
      "Lucy thought for a moment and then said, \"I guess I'll have to get the balloon.\"\n",
      "\n",
      "The man smiled and said, \"That's a good guess! Here you go.\"\n",
      "\n",
      "Lucy was so happy and thanked the man. She hugged the balloon and ran off to show her mom.\n",
      "\n",
      "The end.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# built-in helper to get tinystore\n",
    "_, tokenizer, tinystory = pv.create_gpt_neo()\n",
    "emb_happy = tinystory.transformer.wte(\n",
    "    torch.tensor(14628)) * 0.3\n",
    "\n",
    "pv_tinystory = pv.IntervenableModel([{\n",
    "    \"layer\": _,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"intervention_type\": pv.AdditionIntervention\n",
    "    } for _ in range(\n",
    "        tinystory.config.num_layers)],\n",
    "    model=tinystory)\n",
    "\n",
    "prompt = tokenizer(\n",
    "    \"Once upon a time there was\", \n",
    "    return_tensors=\"pt\")\n",
    "_, intervened_story = pv_tinystory.generate(\n",
    "    prompt,\n",
    "    source_representations=emb_happy,\n",
    "    max_length=256\n",
    ")\n",
    "print(tokenizer.decode(\n",
    "    intervened_story[0], \n",
    "    skip_special_tokens=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb539f4b",
   "metadata": {},
   "source": [
    "### saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272f3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "Directory './tmp/' already exists.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# run with new intervention type\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "  \"intervention_type\": pv.ZeroIntervention}, \n",
    "  model=gpt2)\n",
    "\n",
    "pv_gpt2.save(\"./tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b894b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.\n",
      "WARNING:root:Loading trainable intervention from intkey_layer.0.repr.block_output.unit.pos.nunit.1#0.bin.\n"
     ]
    }
   ],
   "source": [
    "pv_gpt2 = pv.IntervenableModel.load(\n",
    "    \"./tmp/\",\n",
    "    model=gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7ccad",
   "metadata": {},
   "source": [
    "## to add a little more complexity\n",
    "\n",
    "### intervention grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84afd62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \"group_key\": 0},\n",
    "    {\"layer\": 2, \"component\": \"block_output\", \"group_key\": 0}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")]\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, sources, \n",
    "    {\"sources->base\": ([\n",
    "        [[3]], [[4]] # these two are for two interventions\n",
    "    ], [             # source position 3 into base position 4\n",
    "        [[3]], [[4]] \n",
    "    ])}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aeb892",
   "metadata": {},
   "source": [
    "### dynamically intervention skipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61cd8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # these are equivalent interventions\n",
    "    # we create them on purpose\n",
    "    {\"layer\": 0, \"component\": \"block_output\"},\n",
    "    {\"layer\": 0, \"component\": \"block_output\"},\n",
    "    {\"layer\": 0, \"component\": \"block_output\"}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "# skipping 1, 2 and 3\n",
    "_, pv_out1 = pv_gpt2(base, [None, None, source],\n",
    "    {\"sources->base\": ([None, None, [[4]]], [None, None, [[4]]])})\n",
    "_, pv_out2 = pv_gpt2(base, [None, source, None],\n",
    "    {\"sources->base\": ([None, [[4]], None], [None, [[4]], None])})\n",
    "_, pv_out3 = pv_gpt2(base, [source, None, None],\n",
    "    {\"sources->base\": ([[[4]], None, None], [[[4]], None, None])})\n",
    "# should have the same results\n",
    "print(\n",
    "    torch.equal(pv_out1.last_hidden_state, pv_out2.last_hidden_state),\n",
    "    torch.equal(pv_out2.last_hidden_state, pv_out3.last_hidden_state)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df6acd",
   "metadata": {},
   "source": [
    "### intervening on subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a66bbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     # subspaces can be partitioned into continuous chunks\n",
    "     # [i, j] are the boundary indices\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]]}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "# using intervention skipping for subspace\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, [source],\n",
    "    {\"sources->base\": 4},\n",
    "    # intervene only only dimensions from 128 to 256\n",
    "    subspaces=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdde257",
   "metadata": {},
   "source": [
    "### linked/coupled interventions for weights sharing and subspace interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec19da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \n",
    "     \"subspace_partition\": [[0, 128], [128, 256]], \"intervention_link_key\": 0},\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]], \"intervention_link_key\": 0}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "# using intervention skipping for subspace\n",
    "_, pv_out1 = pv_gpt2(\n",
    "    base, [None, source],\n",
    "    # 4 means token position 4\n",
    "    {\"sources->base\": ([None, [[4]]], [None, [[4]]])},\n",
    "    # 1 means the second partition in the config\n",
    "    subspaces=[None, [[1]]],\n",
    ")\n",
    "_, pv_out2 = pv_gpt2(\n",
    "    base,\n",
    "    [source, None],\n",
    "    {\"sources->base\": ([[[4]], None], [[[4]], None])},\n",
    "    subspaces=[[[1]], None],\n",
    ")\n",
    "print(torch.equal(pv_out1.last_hidden_state, pv_out2.last_hidden_state))\n",
    "\n",
    "# subspaces provide a list of index and they can be in any order\n",
    "_, pv_out3 = pv_gpt2(\n",
    "    base,\n",
    "    [source, source],\n",
    "    {\"sources->base\": ([[[4]], [[4]]], [[[4]], [[4]]])},\n",
    "    subspaces=[[[0]], [[1]]],\n",
    ")\n",
    "_, pv_out4 = pv_gpt2(\n",
    "    base,\n",
    "    [source, source],\n",
    "    {\"sources->base\": ([[[4]], [[4]]], [[[4]], [[4]]])},\n",
    "    subspaces=[[[1]], [[0]]],\n",
    ")\n",
    "print(torch.equal(pv_out3.last_hidden_state, pv_out4.last_hidden_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b7a3e",
   "metadata": {},
   "source": [
    "### adding new model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acce6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# get a flan-t5 from HuggingFace\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "config = T5Config.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "t5 = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/flan-t5-small\", config=config\n",
    ")\n",
    "\n",
    "# config the intervention mapping with pv global vars\n",
    "\"\"\"Only define for the block output here for simplicity\"\"\"\n",
    "pv.type_to_module_mapping[type(t5)] = {\n",
    "    \"mlp_output\": (\"encoder.block[%s].layer[1]\", \n",
    "                   pv.models.constants.CONST_OUTPUT_HOOK),\n",
    "    \"attention_input\": (\"encoder.block[%s].layer[0]\", \n",
    "                        pv.models.constants.CONST_OUTPUT_HOOK),\n",
    "}\n",
    "pv.type_to_dimension_mapping[type(t5)] = {\n",
    "    \"mlp_output\": (\"d_model\",),\n",
    "    \"attention_input\": (\"d_model\",),\n",
    "    \"block_output\": (\"d_model\",),\n",
    "    \"head_attention_value_output\": (\"d_model/num_heads\",),\n",
    "}\n",
    "\n",
    "# wrap as gpt2\n",
    "pv_t5 = pv.IntervenableModel({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"source_representation\": torch.zeros(\n",
    "        t5.config.d_model)\n",
    "}, model=t5)\n",
    "\n",
    "# then intervene!\n",
    "base = tokenizer(\"The capital of Spain is\", \n",
    "                 return_tensors=\"pt\")\n",
    "decoder_input_ids = tokenizer(\n",
    "    \"\", return_tensors=\"pt\").input_ids\n",
    "base[\"decoder_input_ids\"] = decoder_input_ids\n",
    "intervened_outputs = pv_t5(\n",
    "    base, \n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6eb49d",
   "metadata": {},
   "source": [
    "### The End\n",
    "Now you are graduating from pyvene 101! Feel free to take a look at our tutorials for more challenging interventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
