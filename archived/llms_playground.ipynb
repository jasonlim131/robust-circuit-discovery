{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930a8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, LlamaTokenizer\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re, torch\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.modelings_alignable_llama import *\n",
    "from utils.train_utils import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bce26e",
   "metadata": {},
   "source": [
    "#### Loading Alpaca-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1951f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../alpaca_test/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"../../alpaca_test/\",\n",
      "  \"architectures\": [\n",
      "    \"AlignableLlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file ../../alpaca_test/pytorch_model.bin\n",
      "Instantiating AlignableLlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing AlignableLlamaForCausalLM.\n",
      "\n",
      "All the weights of AlignableLlamaForCausalLM were initialized from the model checkpoint at ../../alpaca_test/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlignableLlamaForCausalLM for predictions without further training.\n",
      "loading configuration file ../../alpaca_test/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alignment_config = {\n",
    "    'layer': 15,\n",
    "    \"token_range\" : [81, 82]\n",
    "}\n",
    "model = AlignableLlamaForCausalLM.from_pretrained(\n",
    "    \"../../alpaca_test/\",\n",
    "    alignment_config=alignment_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "_ = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa457bb",
   "metadata": {},
   "source": [
    "#### Loading Alpaca-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6ba345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../alpaca_7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/self/scr-sync/nlp/huggingface_hub_llms/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LLaMAForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file ../../alpaca_7b/pytorch_model.bin.index.json\n",
      "Instantiating AlignableLlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d10add2fba45dfa1c93cd16a9cb299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing AlignableLlamaForCausalLM.\n",
      "\n",
      "Some weights of AlignableLlamaForCausalLM were not initialized from the model checkpoint at ../../alpaca_7b/ and are newly initialized: ['model.rotate_layer.parametrizations.weight.original', 'model.intervention_population', 'model.inverse_rotate_layer.lin_layer.parametrizations.weight.original', 'model.temperature', 'model.intervention_boundaries']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file ../../alpaca_7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": -1,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "alignment_config = {\n",
    "    'layer': 15,\n",
    "    \"token_range\" : [81, 82]\n",
    "}\n",
    "model = AlignableLlamaForCausalLM.from_pretrained(\n",
    "    \"../../alpaca_7b/\",\n",
    "    alignment_config=alignment_config,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "_ = model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"../../alpaca_7b/\",\n",
    "    cache_dir=CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt_template = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "%s\n",
    "\n",
    "### Input:\n",
    "%s\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "alpaca_prompt_template_no_inputs = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "%s\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c38394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afc label = Yes (26.0/25.75) ; pred label = Yes\n"
     ]
    }
   ],
   "source": [
    "alpaca_instruction = \"\"\"Please say yes only if Sam is heavier than John, otherwise no.\"\"\"\n",
    "prompt = alpaca_prompt_template % (alpaca_instruction, \"Sam weigh 112 lbs, John weigh 163 lbs\")\n",
    "\n",
    "# alpaca_instruction = \"\"\"Does Donald Trump use computer?\"\"\"\n",
    "# prompt = alpaca_prompt_template_no_inputs % (alpaca_instruction)\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "attention_mask = tokenizer(prompt, return_tensors=\"pt\").attention_mask.to(\"cuda\")\n",
    "model.eval()\n",
    "outputs = model(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask\n",
    ")\n",
    "pred_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "generated_tokens = tokenizer.decode(pred_labels[0])\n",
    "\n",
    "afc_1 = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "afc_2 = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "afc_1_prob = outputs.logits[:, -1][0][afc_1]\n",
    "afc_2_prob = outputs.logits[:, -1][0][afc_2]\n",
    "if afc_1_prob > afc_2_prob:\n",
    "    afc = \"Yes\"\n",
    "else:\n",
    "    afc = \"No\"\n",
    "print(f\"afc label = {afc} ({afc_1_prob}/{afc_2_prob}) ; pred label = {generated_tokens}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cac3d8",
   "metadata": {},
   "source": [
    "#### Factual: Pricing Tag Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8659bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler(\n",
    "    tokenizer,\n",
    "    5000,\n",
    "    game=\"pricing_tag\"\n",
    ")\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_prealign[0], \n",
    "        \"labels\": raw_prealign[1],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "prealign_dataloader = DataLoader(\n",
    "    prealign_dataset, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(model.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            labels=inputs['labels'],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['labels'][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "current_acc = round(correct_count/total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f2df4",
   "metadata": {},
   "source": [
    "#### (Experimental) Factual: Pricing Tag Game Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7920a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselining with a random rotation + learned boundary\n"
     ]
    }
   ],
   "source": [
    "checkpoint_state_dict = torch.load(\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.42.intl.15.intr.81.82/pytorch-rotate-best.bin\")\n",
    "baselining = True\n",
    "if baselining:\n",
    "    print(\"Baselining with a random rotation + learned boundary\")\n",
    "    n = model.model.rotate_layer.parametrizations.weight.original.shape[0]\n",
    "    rand_weight = torch.empty(n,n).to(\"cuda\").to(torch.bfloat16)\n",
    "    torch.nn.init.orthogonal_(rand_weight)\n",
    "    model.model.rotate_layer.parametrizations.weight.original.data = rand_weight.data\n",
    "else:\n",
    "    model.model.rotate_layer.load_state_dict(\n",
    "        checkpoint_state_dict['rotate_layer']\n",
    "    )\n",
    "model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f24c8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=2.51,\n",
    "    bound_width=2.00,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e4e39a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(model.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        source_hidden_states = model(\n",
    "            input_ids=inputs['source_input_ids'],\n",
    "            output_rotated_hidden_states_only=True\n",
    "        ).rotated_hidden_states\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            source_hidden_states=source_hidden_states,\n",
    "            intervention_ids=inputs['intervention_ids'],\n",
    "            labels=inputs['labels']\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['labels'][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "current_acc = round(correct_count/total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c377fe",
   "metadata": {},
   "source": [
    "#### Goal: we need to find two good bracket settings to study 0-shot transfer!\n",
    "2.51 to 5.51 seems to be working with 0.95\n",
    "\n",
    "5.49 to 8.49 seems to be working with 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ee4f50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler(\n",
    "    tokenizer,\n",
    "    500,\n",
    "    game=\"pricing_tag\",\n",
    "    amount=None,\n",
    "    lower_bound=2.51,\n",
    "    bound_width=4.00,\n",
    ")\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_prealign[0], \n",
    "        \"labels\": raw_prealign[1],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "prealign_dataloader = DataLoader(\n",
    "    prealign_dataset, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "397cf8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:13<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(model.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            labels=inputs['labels'],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['labels'][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "current_acc = round(correct_count/total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2faa990",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "105ff83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Please say yes only if it costs between 1.23 and 4.56 dollars, otherwise no.\n",
    "\n",
    "### Input:\n",
    "7.89 dollars\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3079c3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<0x0A>',\n",
       " '7',\n",
       " '.',\n",
       " '8',\n",
       " '9',\n",
       " '▁dollars',\n",
       " '<0x0A>',\n",
       " '<0x0A>',\n",
       " '##',\n",
       " '#',\n",
       " '▁Response',\n",
       " ':',\n",
       " '<0x0A>']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(prompt)[68:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec90595",
   "metadata": {},
   "source": [
    "#### Get two evaluation set each with 1K examples\n",
    "one for models getting correct\n",
    "one for models getting wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_triples = set([])\n",
    "correct_triples = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c7e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#correct 6461 ; #incorrect 1039: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:24<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(range(500))\n",
    "    for i in pbar:\n",
    "        input_ids, output_ids, triple = pricing_tag_game_example_sampler_with_info(\n",
    "            tokenizer, None, None, None\n",
    "        )\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(dim=0).to(model.device)\n",
    "        output_ids = torch.tensor(output_ids).unsqueeze(dim=0).to(model.device)\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            labels=output_ids,\n",
    "        )\n",
    "        actual_test_labels = output_ids[0, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[0, -1], dim=-1)\n",
    "        if actual_test_labels == pred_test_labels:\n",
    "            correct_triples.add(triple)\n",
    "        else:\n",
    "            incorrect_triples.add(triple)\n",
    "        pbar.set_description(\"#correct %s ; #incorrect %s\" % (\n",
    "            len(correct_triples), len(incorrect_triples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9cf7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_triples_sampled = random.sample(list(incorrect_triples), k=1000)\n",
    "correct_triples_sampled = random.sample(list(correct_triples), k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652b5f5",
   "metadata": {},
   "source": [
    "#### Re-eval with correct and incorrect triples as well as learned DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ae518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the pickled file for binary reading\n",
    "with open('../logs/consistency_triples.pickle', 'rb') as file:\n",
    "    # Load the pickled object from the file\n",
    "    loaded_object = pickle.load(file)\n",
    "incorrect_triples = loaded_object[\"incorrect_triples\"]\n",
    "correct_triples = loaded_object[\"correct_triples\"]\n",
    "\n",
    "incorrect_triples_by_regions = {\n",
    "    1 : set([]),\n",
    "    2 : set([]),\n",
    "    3 : set([]),\n",
    "}\n",
    "correct_triples_by_regions = {\n",
    "    1 : set([]),\n",
    "    2 : set([]),\n",
    "    3 : set([]),\n",
    "}\n",
    "\n",
    "for t in incorrect_triples:\n",
    "    if t[-1] < t[0]:\n",
    "        incorrect_triples_by_regions[1].add(t)\n",
    "    elif t[-1] > t[1]:\n",
    "        incorrect_triples_by_regions[3].add(t)\n",
    "    else:\n",
    "        incorrect_triples_by_regions[2].add(t)\n",
    "\n",
    "for t in correct_triples:\n",
    "    if t[-1] < t[0]:\n",
    "        correct_triples_by_regions[1].add(t)\n",
    "    elif t[-1] > t[1]:\n",
    "        correct_triples_by_regions[3].add(t)\n",
    "    else:\n",
    "        correct_triples_by_regions[2].add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b57376",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_results = {}\n",
    "incorrect_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf813df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler_with_triples(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler_with_triples,\n",
    "        upper_bound_alignment_example_sampler_with_triples\n",
    "    ],\n",
    "    correct_triples_by_regions\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69]:\n",
    "        for layer_idx in [0, 5, 10, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            correct_results[(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")\n",
    "\n",
    "raw_data = bound_alignment_sampler_with_triples(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler_with_triples,\n",
    "        upper_bound_alignment_example_sampler_with_triples\n",
    "    ],\n",
    "    incorrect_triples_by_regions\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69]:\n",
    "        for layer_idx in [0, 5, 10, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            incorrect_results[(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9973fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval_results_consistency.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        {\"correct_results\" : correct_results, \n",
    "         \"incorrect_results\" : incorrect_results}\n",
    "        , file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66426a2",
   "metadata": {},
   "source": [
    "#### Finding Irrelevant Context Model Can Still Perform\n",
    "\n",
    "\"Pricing tag game!\" (84%)\n",
    "\n",
    "\"LLaMA is not conscious.\" (84%)\n",
    "\n",
    "\"Fruitarian Frogs May Be Doing Flowers a Favor\" (85%; citation: NYT America 04/28 First Story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c02253c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricing_tag_game_example_sampler_with_context(\n",
    "    tokenizer,\n",
    "    context,\n",
    "    amount,\n",
    "    lower_bound,\n",
    "    bound_width,\n",
    "):\n",
    "    lower_bound_sample, upper_bound_sample, amount_sample = pricing_tag_game_config_sampler(\n",
    "        amount,\n",
    "        lower_bound,\n",
    "        bound_width\n",
    "    )\n",
    "    lower_bound_str = \"%.2f\" % lower_bound_sample\n",
    "    upper_bound_str = \"%.2f\" % upper_bound_sample\n",
    "    if amount_sample >= float(lower_bound_str) and amount_sample <= float(upper_bound_str):\n",
    "        label = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "    else:\n",
    "        label = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "\n",
    "    amount_str = \"%.2f dollars\" % amount_sample\n",
    "    instruction = f\"{context} Please say yes only if it costs between {lower_bound_str} and {upper_bound_str} dollars, otherwise no.\"\n",
    "    alpaca_prompt = alpaca_prompt_template % (instruction, amount_str)\n",
    "\n",
    "    input_ids = tokenizer(alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "    output_ids = (torch.ones(input_ids.shape[0])*-100).long().tolist()\n",
    "    output_ids[-1] = label\n",
    "    input_ids = input_ids.tolist()\n",
    "    \n",
    "    return input_ids, output_ids\n",
    "\n",
    "def factual_sampler_with_context(\n",
    "    tokenizer,\n",
    "    context,\n",
    "    max_n_training_examples,\n",
    "    game=\"pricing_tag\",\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    "):\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_output_ids = [] # this one does not have input ids, etc..\n",
    "    for _ in range(max_n_training_examples):\n",
    "        if \"pricing_tag\" in game:\n",
    "            input_ids, output_ids = pricing_tag_game_example_sampler_with_context(\n",
    "                tokenizer,\n",
    "                context,\n",
    "                amount,\n",
    "                lower_bound,\n",
    "                bound_width\n",
    "            )\n",
    "        elif game == \"continent_retrieval\":\n",
    "            pass\n",
    "        all_input_ids += [input_ids]\n",
    "        all_output_ids += [output_ids]\n",
    "        \n",
    "    return all_input_ids, all_output_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1a89547",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler_with_context(\n",
    "    tokenizer,\n",
    "    \"Fruitarian Frogs May Be Doing Flowers a Favor\",\n",
    "    500,\n",
    "    game=\"pricing_tag\"\n",
    ")\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_prealign[0], \n",
    "        \"labels\": raw_prealign[1],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "prealign_dataloader = DataLoader(\n",
    "    prealign_dataset, batch_size=8\n",
    ")\n",
    "\n",
    "total_count = 0\n",
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(model.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            labels=inputs['labels'],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['labels'][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "current_acc = round(correct_count/total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a85e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_alignment_sampler_with_context(\n",
    "    tokenizer,\n",
    "    base_context,\n",
    "    source_context,\n",
    "    max_n_training_examples,\n",
    "    bound_functors,\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    "):\n",
    "    all_base_input_ids = []\n",
    "    all_source_input_ids = []\n",
    "    all_ctf_output_ids = [] # this one does not have input ids, etc..\n",
    "    all_intervention_ids = []\n",
    "    \n",
    "    for _ in range(max_n_training_examples):\n",
    "        bound_functor = random.choice(bound_functors)\n",
    "        base_lower_bound_sample, base_upper_bound_sample, \\\n",
    "            source_lower_bound_sample, source_upper_bound_sample, \\\n",
    "            base_amount_sample, source_amount_sample, \\\n",
    "            ctf_label, ctf_label_str = bound_functor(\n",
    "                tokenizer,\n",
    "                amount,\n",
    "                lower_bound,\n",
    "                bound_width,\n",
    "            )\n",
    "\n",
    "        base_amount_str = \"%.2f dollars\" % base_amount_sample\n",
    "        source_amount_str = \"%.2f dollars\" % source_amount_sample\n",
    "        base_lower_bound_str = \"%.2f\" % base_lower_bound_sample\n",
    "        base_upper_bound_str = \"%.2f\" % base_upper_bound_sample\n",
    "        source_lower_bound_str = \"%.2f\" % source_lower_bound_sample\n",
    "        source_upper_bound_str = \"%.2f\" % source_upper_bound_sample\n",
    "        \n",
    "        # print(f\"base: [{base_lower_bound_str}, {base_upper_bound_str}], {base_amount_str}\")\n",
    "        # print(f\"source: [{source_lower_bound_str}, {source_upper_bound_str}], {source_amount_str}\")\n",
    "        # print(f\"ctf label: {ctf_label_str}\")\n",
    "        \n",
    "        base_instruction = f\"{base_context} Please say yes only if it costs between {base_lower_bound_str} and {base_upper_bound_str} dollars, otherwise no.\"\n",
    "        source_instruction = f\"{source_context} Please say yes only if it costs between {source_lower_bound_str} and {source_upper_bound_str} dollars, otherwise no.\"\n",
    "        \n",
    "        base_alpaca_prompt = alpaca_prompt_template % (base_instruction, base_amount_str)\n",
    "        source_alpaca_prompt = alpaca_prompt_template % (source_instruction, source_amount_str)\n",
    "        \n",
    "        base_input_ids = tokenizer(base_alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "        source_input_ids = tokenizer(source_alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "        base_input_ids = base_input_ids.tolist()\n",
    "        source_input_ids = source_input_ids.tolist()\n",
    "        ctf_output_ids = (torch.ones(len(base_input_ids))*-100).long().tolist()\n",
    "        ctf_output_ids[-1] = ctf_label\n",
    "        intervention_id = 0 if bound_functor == bound_functors[0] else 1\n",
    "        \n",
    "        all_base_input_ids += [base_input_ids]\n",
    "        all_source_input_ids += [source_input_ids]\n",
    "        \n",
    "        all_ctf_output_ids += [ctf_output_ids]\n",
    "        all_intervention_ids += [intervention_id]\n",
    "        \n",
    "    return all_base_input_ids, all_source_input_ids, all_ctf_output_ids, all_intervention_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "588f5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_context_results = {\n",
    "    \"Pricing tag game!\" : dict(),\n",
    "    \"Fruitarian Frogs May Be Doing Flowers a Favor\" : dict(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e518526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding prefix: Pricing tag game!\n",
      "eval with reindexed token_idx = 75 (69) and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with reindexed token_idx = 75 (69) and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"Pricing tag game!\" # +6\n",
    "\n",
    "# context = \"Fruitarian Frogs May Be Doing Flowers a Favor\" # +15\n",
    "\n",
    "raw_data = bound_alignment_sampler_with_context(\n",
    "    tokenizer,\n",
    "    context,\n",
    "    context,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "        upper_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "if context == \"Pricing tag game!\":\n",
    "    offset = 6\n",
    "elif context == \"Fruitarian Frogs May Be Doing Flowers a Favor\":\n",
    "    offset = 15\n",
    "print(f\"Adding prefix: {context}\")\n",
    "for seed in [42]:\n",
    "    for token_idx in [69]:\n",
    "        for layer_idx in [25, 30]:\n",
    "            token_idx_re = token_idx + offset\n",
    "            end_idx_re = token_idx_re + 1\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with reindexed token_idx = {token_idx_re} ({token_idx}) and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx_re, end_idx_re]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx_re, end_idx_re]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            irrelevant_context_results[context][(layer_idx, token_idx_re)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e919900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding prefix: Fruitarian Frogs May Be Doing Flowers a Favor\n",
      "eval with reindexed token_idx = 84 (69) and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with reindexed token_idx = 84 (69) and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with reindexed token_idx = 84 (69) and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with reindexed token_idx = 84 (69) and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:56<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with reindexed token_idx = 84 (69) and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:58<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# context = \"Pricing tag game!\" # +6\n",
    "\n",
    "context = \"Fruitarian Frogs May Be Doing Flowers a Favor\" # +15\n",
    "\n",
    "raw_data = bound_alignment_sampler_with_context(\n",
    "    tokenizer,\n",
    "    context,\n",
    "    context,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "        upper_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "if context == \"Pricing tag game!\":\n",
    "    offset = 6\n",
    "elif context == \"Fruitarian Frogs May Be Doing Flowers a Favor\":\n",
    "    offset = 15\n",
    "print(f\"Adding prefix: {context}\")\n",
    "for seed in [42]:\n",
    "    for token_idx in [69]:\n",
    "        for layer_idx in [0, 5, 10, 25, 30]:\n",
    "            token_idx_re = token_idx + offset\n",
    "            end_idx_re = token_idx_re + 1\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with reindexed token_idx = {token_idx_re} ({token_idx}) and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx_re, end_idx_re]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx_re, end_idx_re]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            irrelevant_context_results[context][(layer_idx, token_idx_re)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7662d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/eval_results_irrelevant_context.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        irrelevant_context_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ecf27",
   "metadata": {},
   "source": [
    "#### Eval test the main experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f41390aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_eval_results = {\n",
    "    \"lower_bound_alignment\" : dict(),\n",
    "    \"both_bound_alignment\" : dict(),\n",
    "    \"midpoint_alignment\" : dict(),\n",
    "    \"bracket_alignment\" : dict(),\n",
    "}\n",
    "control = True\n",
    "if control:\n",
    "    original_weight = torch.empty(4096, 4096).to(torch.bfloat16).to(model.device)\n",
    "    orth_weights = torch.nn.init.orthogonal_(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2476028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.45\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 70 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 70 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 71 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 71 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.45\n",
      "eval with token_idx = 71 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 71 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 71 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 71 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 71 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 72 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 72 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 72 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 72 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 72 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 72 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 72 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 73 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 74 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 74 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 75 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 75 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 75 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 75 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 75 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 75 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 75 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 76 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.45\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:09<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:10<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:12<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:13<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:15<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:17<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lb.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            if control:\n",
    "                model.model.rotate_layer.weight.data = orth_weights\n",
    "                model.model.rotate_layer.parametrizations.weight.original.data = original_weight\n",
    "            else:\n",
    "                model.model.rotate_layer.load_state_dict(\n",
    "                    checkpoint_state_dict['rotate_layer']\n",
    "                )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            main_eval_results['lower_bound_alignment'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25060958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "        upper_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            main_eval_results['both_bound_alignment'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43e8dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 70 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.66\n",
      "eval with token_idx = 70 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.69\n",
      "eval with token_idx = 70 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 70 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 70 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.66\n",
      "eval with token_idx = 70 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 70 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 71 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 71 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 71 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 71 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 71 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 71 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 71 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 72 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 72 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 72 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 72 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 72 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 72 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 72 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 73 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 73 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 73 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 73 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 73 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 73 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 73 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 74 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 74 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 74 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 74 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 74 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 74 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 74 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 75 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 75 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 75 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 75 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 75 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 75 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 75 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 76 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 76 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.72\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = midpoint_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_mid_diff.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            main_eval_results['midpoint_alignment'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b7033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 70 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n",
      "eval with token_idx = 70 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.66\n",
      "eval with token_idx = 70 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 70 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 70 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 70 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 70 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 71 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 71 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 71 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 71 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 71 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 71 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 71 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 72 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 72 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 72 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 72 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 72 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 72 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 72 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 73 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 73 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 73 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 73 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 73 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 73 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 73 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 74 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 74 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 74 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 74 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 74 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 74 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 74 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 75 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 75 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 75 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 75 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 75 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 75 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 75 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 76 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 76 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 76 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 76 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 76 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 76 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 76 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.71\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bracket_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_bracket.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            main_eval_results['bracket_alignment'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96420dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/eval_main_control_results.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        main_eval_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7be009",
   "metadata": {},
   "source": [
    "#### Zero-shot Transfer between two fixed bounds DAS learning\n",
    "\n",
    "2.51 to 5.51 seems to be working with 0.95\n",
    "\n",
    "5.49 to 8.49 seems to be working with 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d4f7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_results = {\n",
    "    \"original\" : dict(),\n",
    "    \"transfer\" : dict(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ce610e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.67\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.54\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.53\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.79\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.54\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.53\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.9\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.74\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.69\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=2.51,\n",
    "    bound_width=3.00,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_fixed.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            zero_shot_results['transfer'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32285ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.46\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 70 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.92\n",
      "eval with token_idx = 70 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.92\n",
      "eval with token_idx = 70 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.91\n",
      "eval with token_idx = 70 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.88\n",
      "eval with token_idx = 70 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.83\n",
      "eval with token_idx = 70 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.82\n",
      "eval with token_idx = 70 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.74\n",
      "eval with token_idx = 71 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 71 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.9\n",
      "eval with token_idx = 71 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.89\n",
      "eval with token_idx = 71 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.8\n",
      "eval with token_idx = 71 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.78\n",
      "eval with token_idx = 71 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.8\n",
      "eval with token_idx = 71 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.69\n",
      "eval with token_idx = 72 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 72 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.83\n",
      "eval with token_idx = 72 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.87\n",
      "eval with token_idx = 72 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.79\n",
      "eval with token_idx = 72 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n",
      "eval with token_idx = 72 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 72 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 73 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 73 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 73 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.9\n",
      "eval with token_idx = 73 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.83\n",
      "eval with token_idx = 73 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 73 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 73 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 74 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 74 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.54\n",
      "eval with token_idx = 74 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.92\n",
      "eval with token_idx = 74 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.86\n",
      "eval with token_idx = 74 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 74 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 74 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 75 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 75 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 75 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.92\n",
      "eval with token_idx = 75 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.9\n",
      "eval with token_idx = 75 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 75 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 75 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 76 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 76 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 76 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 76 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 76 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 76 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 76 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.76\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.53\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.48\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.91\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.7\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.62\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.47\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.7\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.94\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.92\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.89\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=5.49,\n",
    "    bound_width=3.00,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_fixed.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            zero_shot_results['original'][(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f076b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/eval_zero_shot_results.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        zero_shot_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a625b62",
   "metadata": {},
   "source": [
    "#### Zero-shot sibiling instruction transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f6f9e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricing_tag_game_example_sampler_with_different_return(\n",
    "    tokenizer,\n",
    "    new_labels,\n",
    "    amount,\n",
    "    lower_bound,\n",
    "    bound_width,\n",
    "):\n",
    "    lower_bound_sample, upper_bound_sample, amount_sample = pricing_tag_game_config_sampler(\n",
    "        amount,\n",
    "        lower_bound,\n",
    "        bound_width\n",
    "    )\n",
    "    lower_bound_str = \"%.2f\" % lower_bound_sample\n",
    "    upper_bound_str = \"%.2f\" % upper_bound_sample\n",
    "    if amount_sample >= float(lower_bound_str) and amount_sample <= float(upper_bound_str):\n",
    "        label = tokenizer.convert_tokens_to_ids(new_labels[0])\n",
    "    else:\n",
    "        label = tokenizer.convert_tokens_to_ids(new_labels[1])\n",
    "\n",
    "    amount_str = \"%.2f dollars\" % amount_sample\n",
    "    instruction = f\"Please say {new_labels[0]} only if it costs between {lower_bound_str} and {upper_bound_str} dollars, otherwise {new_labels[1]}.\"\n",
    "    alpaca_prompt = alpaca_prompt_template % (instruction, amount_str)\n",
    "\n",
    "    input_ids = tokenizer(alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "    output_ids = (torch.ones(input_ids.shape[0])*-100).long().tolist()\n",
    "    output_ids[-1] = label\n",
    "    input_ids = input_ids.tolist()\n",
    "    \n",
    "    return input_ids, output_ids\n",
    "\n",
    "def factual_sampler_with_different_return(\n",
    "    tokenizer,\n",
    "    new_labels,\n",
    "    max_n_training_examples,\n",
    "    game=\"pricing_tag\",\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    "):\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_output_ids = [] # this one does not have input ids, etc..\n",
    "    for _ in range(max_n_training_examples):\n",
    "        if \"pricing_tag\" in game:\n",
    "            input_ids, output_ids = pricing_tag_game_example_sampler_with_different_return(\n",
    "                tokenizer,\n",
    "                new_labels,\n",
    "                amount,\n",
    "                lower_bound,\n",
    "                bound_width\n",
    "            )\n",
    "        elif game == \"continent_retrieval\":\n",
    "            pass\n",
    "        all_input_ids += [input_ids]\n",
    "        all_output_ids += [output_ids]\n",
    "        \n",
    "    return all_input_ids, all_output_ids\n",
    "\n",
    "def bound_alignment_sampler_with_different_return(\n",
    "    tokenizer,\n",
    "    new_labels,\n",
    "    max_n_training_examples,\n",
    "    bound_functors,\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    "):\n",
    "    all_base_input_ids = []\n",
    "    all_source_input_ids = []\n",
    "    all_ctf_output_ids = [] # this one does not have input ids, etc..\n",
    "    all_intervention_ids = []\n",
    "    \n",
    "    for _ in range(max_n_training_examples):\n",
    "        bound_functor = random.choice(bound_functors)\n",
    "        base_lower_bound_sample, base_upper_bound_sample, \\\n",
    "            source_lower_bound_sample, source_upper_bound_sample, \\\n",
    "            base_amount_sample, source_amount_sample, \\\n",
    "            ctf_label, ctf_label_str = bound_functor(\n",
    "                tokenizer,\n",
    "                amount,\n",
    "                lower_bound,\n",
    "                bound_width,\n",
    "            )\n",
    "        # overwrite a little\n",
    "        if ctf_label_str == \"Yes\":\n",
    "            ctf_label_str = new_labels[0]\n",
    "            ctf_label = tokenizer.convert_tokens_to_ids(new_labels[0])\n",
    "        elif ctf_label_str == \"No\":\n",
    "            ctf_label_str = new_labels[1]\n",
    "            ctf_label = tokenizer.convert_tokens_to_ids(new_labels[1])\n",
    "\n",
    "        base_amount_str = \"%.2f dollars\" % base_amount_sample\n",
    "        source_amount_str = \"%.2f dollars\" % source_amount_sample\n",
    "        base_lower_bound_str = \"%.2f\" % base_lower_bound_sample\n",
    "        base_upper_bound_str = \"%.2f\" % base_upper_bound_sample\n",
    "        source_lower_bound_str = \"%.2f\" % source_lower_bound_sample\n",
    "        source_upper_bound_str = \"%.2f\" % source_upper_bound_sample\n",
    "        \n",
    "        # print(f\"base: [{base_lower_bound_str}, {base_upper_bound_str}], {base_amount_str}\")\n",
    "        # print(f\"source: [{source_lower_bound_str}, {source_upper_bound_str}], {source_amount_str}\")\n",
    "        # print(f\"ctf label: {ctf_label_str}\")\n",
    "        \n",
    "        base_instruction = f\"Please say {new_labels[0]} only if it costs between {base_lower_bound_str} and {base_upper_bound_str} dollars, otherwise {new_labels[1]}.\"\n",
    "        source_instruction = f\"Please say {new_labels[0]} only if it costs between {source_lower_bound_str} and {source_upper_bound_str} dollars, otherwise {new_labels[1]}.\"\n",
    "        \n",
    "        base_alpaca_prompt = alpaca_prompt_template % (base_instruction, base_amount_str)\n",
    "        source_alpaca_prompt = alpaca_prompt_template % (source_instruction, source_amount_str)\n",
    "        \n",
    "        base_input_ids = tokenizer(base_alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "        source_input_ids = tokenizer(source_alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "        base_input_ids = base_input_ids.tolist()\n",
    "        source_input_ids = source_input_ids.tolist()\n",
    "        ctf_output_ids = (torch.ones(len(base_input_ids))*-100).long().tolist()\n",
    "        ctf_output_ids[-1] = ctf_label\n",
    "        intervention_id = 0 if bound_functor == bound_functors[0] else 1\n",
    "        \n",
    "        all_base_input_ids += [base_input_ids]\n",
    "        all_source_input_ids += [source_input_ids]\n",
    "        \n",
    "        all_ctf_output_ids += [ctf_output_ids]\n",
    "        all_intervention_ids += [intervention_id]\n",
    "        \n",
    "    return all_base_input_ids, all_source_input_ids, all_ctf_output_ids, all_intervention_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b1c7ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prealign = factual_sampler_with_different_return(\n",
    "    tokenizer,\n",
    "    ['True', 'False'],\n",
    "    500,\n",
    "    game=\"pricing_tag\"\n",
    ")\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_prealign[0], \n",
    "        \"labels\": raw_prealign[1],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "prealign_dataloader = DataLoader(\n",
    "    prealign_dataset, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8ae63116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:13<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(model.device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            labels=inputs['labels'],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs['labels'][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "current_acc = round(correct_count/total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c79204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "different_return_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "39187b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 69 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 69 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 70 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.75\n",
      "eval with token_idx = 70 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.75\n",
      "eval with token_idx = 70 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.77\n",
      "eval with token_idx = 70 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.71\n",
      "eval with token_idx = 70 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 70 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 70 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 71 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 71 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.73\n",
      "eval with token_idx = 71 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.79\n",
      "eval with token_idx = 71 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.7\n",
      "eval with token_idx = 71 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 71 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 71 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 72 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 72 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.68\n",
      "eval with token_idx = 72 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.7\n",
      "eval with token_idx = 72 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.72\n",
      "eval with token_idx = 72 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 72 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 72 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 73 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 73 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 73 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.6\n",
      "eval with token_idx = 73 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.64\n",
      "eval with token_idx = 73 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 73 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 73 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 74 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 74 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 74 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.79\n",
      "eval with token_idx = 74 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.7\n",
      "eval with token_idx = 74 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 74 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 74 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 75 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 75 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.56\n",
      "eval with token_idx = 75 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.83\n",
      "eval with token_idx = 75 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.74\n",
      "eval with token_idx = 75 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 75 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 75 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 76 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 76 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 76 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.53\n",
      "eval with token_idx = 76 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 76 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 76 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 76 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.49\n",
      "eval with token_idx = 77 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 77 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 78 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 79 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 79 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 79 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 79 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.57\n",
      "eval with token_idx = 79 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 79 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 79 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:47<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.51\n",
      "eval with token_idx = 80 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.58\n",
      "eval with token_idx = 80 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 80 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 81 and layer_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.5\n",
      "eval with token_idx = 81 and layer_idx = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 81 and layer_idx = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:50<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.56\n",
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.83\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:52<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.65\n",
      "eval with token_idx = 81 and layer_idx = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.59\n",
      "eval with token_idx = 81 and layer_idx = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:55<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler_with_different_return(\n",
    "    tokenizer,\n",
    "    [\"True\", \"False\"],\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_sampler,\n",
    "        upper_bound_alignment_example_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]:\n",
    "        for layer_idx in [0, 5, 10, 15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-best.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            different_return_results[(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a5e53799",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/eval_different_return_results.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        different_return_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b23175",
   "metadata": {},
   "source": [
    "#### Zero-shot between type DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6d0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound_alignment_example_reversed_sampler(\n",
    "    tokenizer,\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None\n",
    "):\n",
    "    base_lower_bound_sample, base_upper_bound_sample, _ = \\\n",
    "        pricing_tag_game_config_sampler(\n",
    "            amount,\n",
    "            lower_bound,\n",
    "            bound_width\n",
    "        )\n",
    "    source_lower_bound_sample, source_upper_bound_sample, _ = \\\n",
    "        pricing_tag_game_config_sampler(\n",
    "            amount,\n",
    "            lower_bound,\n",
    "            bound_width\n",
    "        )\n",
    "    \n",
    "    ctf_label_str = random.choice([\"Yes\", \"No\"])\n",
    "    if ctf_label_str == \"Yes\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "        base_source_regions = [\n",
    "            [1,1],\n",
    "            [1,2],\n",
    "            [2,2],\n",
    "        ]\n",
    "    elif ctf_label_str == \"No\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "        base_source_regions = [\n",
    "            [1,3],\n",
    "            [2,1],\n",
    "            [2,3],\n",
    "            [3,1],\n",
    "            [3,2],\n",
    "            [3,3]\n",
    "        ]\n",
    "    base_source_region = random.choice(base_source_regions)\n",
    "    base_region = base_source_region[0]\n",
    "    source_region = base_source_region[1]\n",
    "\n",
    "    base_amount_sample = sample_with_region(\n",
    "        base_region, base_lower_bound_sample, base_upper_bound_sample)\n",
    "    source_amount_sample = sample_with_region(\n",
    "        source_region, source_lower_bound_sample, source_upper_bound_sample)\n",
    "        \n",
    "    return base_lower_bound_sample, base_upper_bound_sample, \\\n",
    "        source_lower_bound_sample, source_upper_bound_sample, \\\n",
    "        base_amount_sample, source_amount_sample, ctf_label, ctf_label_str\n",
    "    \n",
    "def upper_bound_alignment_example_reversed_sampler(\n",
    "    tokenizer,\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None\n",
    "):\n",
    "    base_lower_bound_sample, base_upper_bound_sample, base_amount_sample = \\\n",
    "        pricing_tag_game_config_sampler(\n",
    "            amount,\n",
    "            lower_bound,\n",
    "            bound_width\n",
    "        )\n",
    "    source_lower_bound_sample, source_upper_bound_sample, source_amount_sample = \\\n",
    "        pricing_tag_game_config_sampler(\n",
    "            amount,\n",
    "            lower_bound,\n",
    "            bound_width\n",
    "        )\n",
    "    \n",
    "    ctf_label_str = random.choice([\"Yes\", \"No\"])\n",
    "    if ctf_label_str == \"Yes\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "        base_source_regions = [\n",
    "            [3,3],\n",
    "            [3,2],\n",
    "            [2,2],\n",
    "        ]\n",
    "    elif ctf_label_str == \"No\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "        base_source_regions = [\n",
    "            [1,1],\n",
    "            [1,2],\n",
    "            [1,3],\n",
    "            [2,1],\n",
    "            [2,3],\n",
    "            [3,1]\n",
    "        ]\n",
    "    base_source_region = random.choice(base_source_regions)\n",
    "    base_region = base_source_region[0]\n",
    "    source_region = base_source_region[1]\n",
    "    \n",
    "    base_amount_sample = sample_with_region(\n",
    "        base_region, base_lower_bound_sample, base_upper_bound_sample)\n",
    "    source_amount_sample = sample_with_region(\n",
    "        source_region, source_lower_bound_sample, source_upper_bound_sample)\n",
    "    \n",
    "    return base_lower_bound_sample, base_upper_bound_sample, \\\n",
    "        source_lower_bound_sample, source_upper_bound_sample, \\\n",
    "        base_amount_sample, source_amount_sample, ctf_label, ctf_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dff34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_transfer_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval with token_idx = 81 and layer_idx = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 125/125 [00:51<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIA accuracy: 0.52\n",
      "eval with token_idx = 81 and layer_idx = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████████▉                                           | 61/125 [00:25<00:26,  2.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/wuzhengx/ipykernel_715931/3467522215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;31m# aligning forward!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     source_hidden_states = model(\n\u001b[0m\u001b[1;32m     68\u001b[0m                         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0moutput_rotated_hidden_states_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/wuzhengx/ToM-Alignment/archived/../models/modelings_alignable_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, source_input_ids, source_hidden_states, intervention_ids, output_rotated_hidden_states_only, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/wuzhengx/ToM-Alignment/archived/../models/modelings_alignable_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, source_hidden_states, intervention_ids, output_rotated_hidden_states_only, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mprefix_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mpostfix_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mrotated_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligning_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# intervene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/wuzhengx/ToM-Alignment/archived/../models/modelings_alignable_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAlignableLlamaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLlamaModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/utils/parametrize.py\u001b[0m in \u001b[0;36mget_parametrized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;31m# If caching is not active, this function just evaluates the parametrization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mparametrization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/utils/parametrize.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Unpack the originals for the first parametrization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0moriginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"original{i}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-bootleg/lib/python3.8/site-packages/torch/nn/utils/parametrizations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# A is skew-symmetric (or skew-hermitian)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morthogonal_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_OrthMaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morthogonal_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_OrthMaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcayley\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m# Computes the Cayley retraction (I+A/2)(I-A/2)^{-1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_data = bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    1000,\n",
    "    [\n",
    "        lower_bound_alignment_example_reversed_sampler,\n",
    "        upper_bound_alignment_example_reversed_sampler,\n",
    "    ],\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0], \n",
    "    raw_data[1], \n",
    "    raw_data[2],\n",
    "    raw_data[3]\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0], \n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=8,\n",
    ")\n",
    "\n",
    "# grid search\n",
    "# [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "# [0, 5, 10, 15, 20, 25, 30]\n",
    "for seed in [42]:\n",
    "    for token_idx in [81]:\n",
    "        for layer_idx in [15, 20, 25, 30]:\n",
    "            end_idx = token_idx + 1\n",
    "            print(f\"eval with token_idx = {token_idx} and layer_idx = {layer_idx}\")\n",
    "            checkpoint_state_dict = torch.load(f\"../results_alpaca-7b/alpaca-7B.task.pricing_tag_lub.seed.{seed}.intl.{layer_idx}.intr.{token_idx}.{end_idx}/pytorch-rotate-last.bin\")\n",
    "            model.model.rotate_layer.load_state_dict(\n",
    "                checkpoint_state_dict['rotate_layer']\n",
    "            )\n",
    "            model.model.intervention_boundaries.data = checkpoint_state_dict['intervention_boundaries'].data\n",
    "            intervention_boundaries = model.model.intervention_boundaries.data\n",
    "            intervention_boundaries = torch.clamp(intervention_boundaries, 1e-3, 1)\n",
    "            start_idx_1 = 0\n",
    "            end_idx_1 = int((model.model.searchable_n_embd//2) * intervention_boundaries[0])\n",
    "            start_idx_2 = end_idx_1\n",
    "            end_idx_2 = end_idx_1 * 2\n",
    "            model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            model.model.alignment_config = {\n",
    "                'layer': layer_idx,\n",
    "                \"token_range\" : [token_idx, end_idx]\n",
    "            }\n",
    "            \n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            with torch.no_grad():\n",
    "                for step, inputs in enumerate(tqdm(test_dataloader)):\n",
    "                    for k, v in inputs.items():\n",
    "                        if v is not None and isinstance(v, torch.Tensor):\n",
    "                            inputs[k] = v.to(model.device)\n",
    "\n",
    "                    # aligning forward!\n",
    "                    source_hidden_states = model(\n",
    "                        input_ids=inputs['source_input_ids'],\n",
    "                        output_rotated_hidden_states_only=True\n",
    "                    ).rotated_hidden_states\n",
    "                    \n",
    "                    # do a hard snapped swap of aligned reprs.\n",
    "                    chunk_1 = source_hidden_states[:,start_idx_1:end_idx_1].clone()\n",
    "                    chunk_2 = source_hidden_states[:,start_idx_2:end_idx_2].clone()\n",
    "                    source_hidden_states[:,start_idx_2:end_idx_2] = chunk_1\n",
    "                    source_hidden_states[:,start_idx_1:end_idx_1] = chunk_2\n",
    "                    \n",
    "                    outputs = model(\n",
    "                        input_ids=inputs['input_ids'],\n",
    "                        source_hidden_states=source_hidden_states,\n",
    "                        intervention_ids=inputs['intervention_ids'],\n",
    "                        labels=inputs['labels']\n",
    "                    )\n",
    "\n",
    "                    actual_test_labels = inputs['labels'][:, -1]\n",
    "                    pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "                    correct_labels = (actual_test_labels==pred_test_labels)\n",
    "\n",
    "                    total_count += len(correct_labels)\n",
    "                    correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "            current_acc = round(correct_count/total_count, 2)\n",
    "            type_transfer_results[(layer_idx, token_idx)] = current_acc\n",
    "            print(f\"IIA accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8438869",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../logs/eval_type_transfer_results.pkl', 'wb') as file:\n",
    "    pickle.dump(\n",
    "        type_transfer_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf101a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
